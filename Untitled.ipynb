{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, Sentence\n",
    "\n",
    "from flair.embeddings import FlairEmbeddings, ELMoEmbeddings\n",
    "\n",
    "# init embedding\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "\n",
    "# create a sentence\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# embed words in sentence\n",
    "flair_embedding_forward.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Union\n",
    "import logging\n",
    "log = logging.getLogger(\"flair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary:\n",
    "    \"\"\"\n",
    "    This class holds a dictionary that maps strings to IDs, used to generate one-hot encodings of strings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, add_unk=True):\n",
    "        # init dictionaries\n",
    "        self.item2idx: Dict[str, int] = {}\n",
    "        self.idx2item: List[str] = []\n",
    "        self.multi_label: bool = False\n",
    "\n",
    "        # in order to deal with unknown tokens, add <unk>\n",
    "        if add_unk:\n",
    "            self.add_item(\"<unk>\")\n",
    "\n",
    "    def add_item(self, item: str) -> int:\n",
    "        \"\"\"\n",
    "        add string - if already in dictionary returns its ID. if not in dictionary, it will get a new ID.\n",
    "        :param item: a string for which to assign an id.\n",
    "        :return: ID of string\n",
    "        \"\"\"\n",
    "        item = item.encode(\"utf-8\")\n",
    "        if item not in self.item2idx:\n",
    "            self.idx2item.append(item)\n",
    "            self.item2idx[item] = len(self.idx2item) - 1\n",
    "        return self.item2idx[item]\n",
    "\n",
    "    def get_idx_for_item(self, item: str) -> int:\n",
    "        \"\"\"\n",
    "        returns the ID of the string, otherwise 0\n",
    "        :param item: string for which ID is requested\n",
    "        :return: ID of string, otherwise 0\n",
    "        \"\"\"\n",
    "        item = item.encode(\"utf-8\")\n",
    "        if item in self.item2idx.keys():\n",
    "            return self.item2idx[item]\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def get_items(self) -> List[str]:\n",
    "        items = []\n",
    "        for item in self.idx2item:\n",
    "            items.append(item.decode(\"UTF-8\"))\n",
    "        return items\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.idx2item)\n",
    "\n",
    "    def get_item_for_index(self, idx):\n",
    "        return self.idx2item[idx].decode(\"UTF-8\")\n",
    "\n",
    "    def save(self, savefile):\n",
    "        import pickle\n",
    "\n",
    "        with open(savefile, \"wb\") as f:\n",
    "            mappings = {\"idx2item\": self.idx2item, \"item2idx\": self.item2idx}\n",
    "            pickle.dump(mappings, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_file(cls, filename: str):\n",
    "        import pickle\n",
    "\n",
    "        dictionary: Dictionary = Dictionary()\n",
    "        with open(filename, \"rb\") as f:\n",
    "            mappings = pickle.load(f, encoding=\"latin1\")\n",
    "            idx2item = mappings[\"idx2item\"]\n",
    "            item2idx = mappings[\"item2idx\"]\n",
    "            dictionary.item2idx = item2idx\n",
    "            dictionary.idx2item = idx2item\n",
    "        return dictionary\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, name: str):\n",
    "        from flair.file_utils import cached_path\n",
    "\n",
    "        if name == \"chars\" or name == \"common-chars\":\n",
    "            base_path = \"https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models/common_characters\"\n",
    "            char_dict = cached_path(base_path, cache_dir=\"datasets\")\n",
    "            return Dictionary.load_from_file(char_dict)\n",
    "\n",
    "        return Dictionary.load_from_file(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.file_utils import Tqdm\n",
    "def make_label_dictionarya(self) -> Dictionary:\n",
    "        \"\"\"\n",
    "        Creates a dictionary of all labels assigned to the sentences in the corpus.\n",
    "        :return: dictionary of labels\n",
    "        \"\"\"\n",
    "        label_dictionary: Dictionary = Dictionary(add_unk=False)\n",
    "        label_dictionary.multi_label = False\n",
    "\n",
    "        from datasets import DataLoader\n",
    "\n",
    "        loader = DataLoader(self.train, batch_size=1)\n",
    "\n",
    "        log.info(\"Computing label dictionary. Progress:\")\n",
    "        for batch in Tqdm.tqdm(iter(loader)):\n",
    "\n",
    "            for sentence in batch:\n",
    " \n",
    "\n",
    "                for label in sentence.labels:\n",
    "                    label_dictionary.add_item(label.value)\n",
    "\n",
    "                if not label_dictionary.multi_label:\n",
    "                    if len(sentence.labels) > 1:\n",
    "                        label_dictionary.multi_label = True\n",
    "\n",
    "        log.info(label_dictionary.idx2item)\n",
    "\n",
    "        return label_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Corpus\n",
    "from datasets import ClassificationCorpus\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = './'\n",
    "\n",
    "# load corpus containing training, test and dev data\n",
    "corpus: Corpus = ClassificationCorpus(data_folder,\n",
    "                                      test_file='test.txt',\n",
    "                                      dev_file='dev.txt',\n",
    "                                      train_file='train.txt')\n",
    "\n",
    "\n",
    "# 2. create the label dictionary\n",
    "label_dict = make_label_dictionarya(corpus)\n",
    "print(get_label_distribution(corpus))\n",
    "\n",
    "# 3. make a list of word embeddings\n",
    "word_embeddings = [WordEmbeddings('glove'),\n",
    "\n",
    "                   # comment in flair embeddings for state-of-the-art results\n",
    "                   # FlairEmbeddings('news-forward'),\n",
    "                   # FlairEmbeddings('news-backward'),\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. initialize document embedding by passing list of word embeddings\n",
    "# Can choose between many RNN types (GRU by default, to change use rnn_type parameter)\n",
    "document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,\n",
    "                                                                     hidden_size=512,\n",
    "                                                                     reproject_words=True,\n",
    "                                                                     reproject_words_dimension=256,\n",
    "                                                                     )\n",
    "\n",
    "# 5. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
    "\n",
    "# 6. initialize the text classifier trainer\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "# 7. start the training\n",
    "trainer.train('resources/taggers/ag_news',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              anneal_factor=0.5,\n",
    "              patience=5,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import FlairEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "# init embedding\n",
    "flair_embedding_forward = FlairEmbeddings(model = 'news-forward')\n",
    "\n",
    "print('pt loaded')\n",
    "\n",
    "# create a sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# embed words in sentence\n",
    "flair_embedding_forward.embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    token_embedding = token.embedding\n",
    "    print(token_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding = ELMoEmbeddings('small')\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "\n",
    "sentence = Sentence('the grass is green .')\n",
    "\n",
    "glove_embedding.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in sentence:\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a sentence. This is another sentence.\"\n",
    "\n",
    "from segtok.segmenter import split_single\n",
    "#sentences = [Sentence(sent, use_tokenizer=True) for sent in split_single(text)]\n",
    "sentences = [sent for sent in split_single(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_embedding_forward.embed(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indiv_sentence in sentences:\n",
    "    for token in indiv_sentence:\n",
    "        print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "words = []\n",
    "idx = 0\n",
    "word2idx = {}\n",
    "vectors = bcolz.carray(np.zeros(1), rootdir=f'./Data/6B.100.dat', mode='w')\n",
    "\n",
    "with open(f'./Data/glove.6B.100d.txt', 'rb') as f:\n",
    "    for l in f:\n",
    "        line = l.decode().split()\n",
    "        word = line[0]\n",
    "        words.append(word)\n",
    "        word2idx[word] = idx\n",
    "        idx += 1\n",
    "        vect = np.array(line[1:]).astype(np.float)\n",
    "        vectors.append(vect)\n",
    "    \n",
    "vectors = bcolz.carray(vectors[1:].reshape((400000, 100)), rootdir=f'./Data/6B.100.dat', mode='w')\n",
    "vectors.flush()\n",
    "pickle.dump(words, open(f'./Data/6B.100_words.pkl', 'wb'))\n",
    "pickle.dump(word2idx, open(f'./Data/6B.100_idx.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = bcolz.open(f'./Data/6B.100.dat')[:]\n",
    "words = pickle.load(open(f'./Data/6B.100_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open(f'./Data/6B.100_idx.pkl', 'rb'))\n",
    "\n",
    "glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segtok.tokenizer import split_contractions\n",
    "from segtok.tokenizer import word_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from itertools import *\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "hdf5_file='./HDF5_files/hdf5_10.hdf5'\n",
    "h5_file = h5py.File(hdf5_file, \"r\")\n",
    "ocr = h5_file.get('train_ocrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_full = []\n",
    "for counter, text in enumerate(ocr):\n",
    "    contractions = split_contractions(word_tokenizer(text))\n",
    "    for element in contractions:\n",
    "        element = element.lower()\n",
    "        contractions_full.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contractions_full)\n",
    "target_vocab = contractions_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim =100\n",
    "matrix_len = len(target_vocab)\n",
    "print(matrix_len)\n",
    "weights_matrix = np.zeros((matrix_len, 100))\n",
    "words_found = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word in enumerate(target_vocab):\n",
    "    try: \n",
    "        weights_matrix[i] = glove[word]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.size()\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenetv3 import mobilenetv3_large, mobilenetv3_small\n",
    "\n",
    "net_large = mobilenetv3_large()\n",
    "\n",
    "net_large.load_state_dict(torch.load('./pretrained/mobilenetv3-large-657e7b3d.pth',map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.imagenet import mobilenetv2\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mobilenetv2()\n",
    "net.load_state_dict(torch.load('pretrained/mobilenetv2_1.0-0c6065bc.pth', map_location='cpu'))\n",
    "feature_extracting = True\n",
    "set_parameter_requires_grad(net, feature_extracting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.classifier = nn.Linear(1280, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extracting:\n",
    "    params_to_update = []\n",
    "    for name,param in net.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in net.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_model):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        #self.args = args\n",
    "        \n",
    "        #V = args.embed_num\n",
    "        D = 2048 #embed_dim, 4196 for doc_embeddings\n",
    "        C = 10 #class_num\n",
    "        Ci = 1\n",
    "        Co = 100 #kernel_num -> number of kernel with the same size\n",
    "        Ks = [3,4,5] #kernel_sizes -> size = number of words\n",
    "\n",
    "        #self.embed = nn.Embedding(V, D)\n",
    "        # self.convs1 = [nn.Conv2d(Ci, Co, (K, D)) for K in Ks]\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        self.conv13 = nn.Conv2d(Ci, Co, (3, D))\n",
    "        self.conv14 = nn.Conv2d(Ci, Co, (4, D))\n",
    "        self.conv15 = nn.Conv2d(Ci, Co, (5, D))\n",
    "        '''\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "        \n",
    "        self.image_model = image_model\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        \n",
    "        #Output will be size (1,Ks*Co) -> Maxpool will get one ĉ value =  max(c_1,c_2...), where c_i is\n",
    "        #the result of the convolution operation of the kernel over the input\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "    def forward(self, x, x2):\n",
    "        #x = self.embed(x)  # (N, W, D)\n",
    "        \n",
    "        #if self.args.static:\n",
    "            #x = Variable(x)\n",
    "        #print('CNN Text entry',x.shape)\n",
    "\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "        #print('unsqueeze',x.shape)\n",
    "        \n",
    "        \n",
    "        #print(x.shape)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
    "        \n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "        \n",
    "\n",
    "        x = torch.cat(x, 1) #[1,100] + [1,100] + [1,100] = [1,300]\n",
    "        \n",
    "        #print('After cat', x.shape)\n",
    "\n",
    "        '''\n",
    "        x1 = self.conv_and_pool(x,self.conv13) #(N,Co)\n",
    "        x2 = self.conv_and_pool(x,self.conv14) #(N,Co)\n",
    "        x3 = self.conv_and_pool(x,self.conv15) #(N,Co)\n",
    "        x = torch.cat((x1, x2, x3), 1) # (N,len(Ks)*Co)\n",
    "        '''\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        \n",
    "        x2 = self.image_model(x2)\n",
    "        \n",
    "        x2 = torch.cat((x,x2),1)\n",
    "        \n",
    "        \n",
    "        logit = x2\n",
    "        #logit = self.fc1(x)  # (N, C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = CNN_Text(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './resources/combined'\n",
    "flair_embedding_forward = FlairEmbeddings('./Data/news-forward-0.4.1.pt')\n",
    "\n",
    "# Dataset creation with image directory, image -> 'RGB' -> transformed to Mobilenetv2 input, Ocr,\n",
    "# Class and Segmentation\n",
    "__all__ = ['MobileNetV2', 'mobilenetv2_19']\n",
    "\n",
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.RandomCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])}\n",
    "#Independent train and test transformations can be done\n",
    "h5_dataset = H5Dataset(path='./HDF5_files/hdf5_small_tobacco_cover.hdf5', data_transforms=data_transforms['train'], embedding_model = flair_embedding_forward, phase = 'train')\n",
    "\n",
    "dataloader_train = DataLoader(h5_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "# for x in dataloader:\n",
    "#     x = x.to('cuda', non_blocking=True)\n",
    "\n",
    "#https://github.com/d-li14/mobilenetv2.pytorch\n",
    "net = mobilenetv2()\n",
    "net.load_state_dict(torch.load('pretrained/mobilenetv2_1.0-0c6065bc.pth'))\n",
    "feature_extracting = True\n",
    "set_parameter_requires_grad(net, feature_extracting)\n",
    "net.classifier = nn.Linear(1280, 300)\n",
    "\n",
    "# get model\n",
    "model = CNN_Text(net)\n",
    "#print(model)\n",
    "# define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# set optimize\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.00004)\n",
    "\n",
    "max_epochs = 1\n",
    "optimizer = optimizer_ft\n",
    "batch_size=1\n",
    "running_loss = 0.0\n",
    "loss_values = []\n",
    "epoch_values = []\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    running_loss = 0\n",
    "    steps = 0\n",
    "    # Training\n",
    "    print('Antes del loop')\n",
    "    for local_batch in dataloader_train:\n",
    "        image, ocr_text, labels = Variable(local_batch['image']), Variable(local_batch['ocr']), Variable(local_batch['class'])\n",
    "        #print(ocr_text.shape)\n",
    "        steps += 1\n",
    "        if ocr_text.shape[1]< 5:\n",
    "            print(steps)\n",
    "            pass\n",
    "        else:\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            #print(local_batch['image_dir'])\n",
    "\n",
    "            # forward\n",
    "            outputs = model(ocr_text, image)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            #print(preds, labels.long())\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            #print(outputs)\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #running_loss += loss.data[0]\n",
    "            if steps % 100 == 0:\n",
    "                print(steps)\n",
    "                #save(model,'./snapshot/', 'model', steps)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    #print(outputs)\n",
    "    print('[Epoch {}/{}], loss {}'.format(\n",
    "                    epoch, max_epochs,running_loss/800))\n",
    "\n",
    "    loss_values.append(running_loss/800)\n",
    "    epoch_values.append(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tobaco3482 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x7fb0d944e0b8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bscuser/anaconda3/envs/dl/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: 'U' mode is deprecated\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_dir</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>ocr_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza37d00/20734258...</td>\n",
       "      <td>Note</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza37d00/20734258...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/r/zzr47c00/20722058...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/r/zzr47c00/20722058...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./SmallTobacco/imagesv/v/a/k/vak71f00/20160034...</td>\n",
       "      <td>News</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesv/v/a/k/vak71f00/20160034...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/g/zzg93e00/20510443...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/g/zzg93e00/20510443...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/j/zzj90e00/91985231...</td>\n",
       "      <td>Note</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/j/zzj90e00/91985231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf4aa00/10384492...</td>\n",
       "      <td>Note</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf4aa00/10384492...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/m/zzm72c00/20783394...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/m/zzm72c00/20783394...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/j/zzj8aa00/11019361...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/j/zzj8aa00/11019361...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/t/zzt65d00/50447313...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/t/zzt65d00/50447313...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/c/zzc47d00/20703610...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/c/zzc47d00/20703610...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw6aa00/50007953...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw6aa00/50007953...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/q/zzq99c00/40044277...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/q/zzq99c00/40044277...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/u/zzu40e00/03523378...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/u/zzu40e00/03523378...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/n/zzn25e00/20286762...</td>\n",
       "      <td>Form</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/n/zzn25e00/20286762...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/b/zzb81d00/656421.png</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/b/zzb81d00/656421.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza03a00/51861750...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza03a00/51861750...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/h/zzh28e00/10008165...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/h/zzh28e00/10008165...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/u/zzu09e00/20506634...</td>\n",
       "      <td>Form</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/u/zzu09e00/20506634...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/p/zzp15c00/25054302...</td>\n",
       "      <td>Form</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/p/zzp15c00/25054302...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/j/zzj18d00/20478702...</td>\n",
       "      <td>News</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/j/zzj18d00/20478702...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/u/zzu37d00/20704226...</td>\n",
       "      <td>News</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/u/zzu37d00/20704226...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/p/zzp79c00/50224756...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/p/zzp79c00/50224756...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/o/zzo38e00/10019069...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/o/zzo38e00/10019069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/x/zzx99d00/85651109...</td>\n",
       "      <td>Note</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/x/zzx99d00/85651109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw29d00/50187147...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw29d00/50187147...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/t/zzt12d00/71375081...</td>\n",
       "      <td>Form</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/t/zzt12d00/71375081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza35e00/20250164...</td>\n",
       "      <td>ADVE</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza35e00/20250164...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/b/zzb09d00/50426112...</td>\n",
       "      <td>Resume</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/b/zzb09d00/50426112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/y/zzy20e00/92064329...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/y/zzy20e00/92064329...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/v/zzv16e00/20546414...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/v/zzv16e00/20546414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/y/zzy28d00/20717608...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/y/zzy28d00/20717608...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/z/zzz50e00/82918230...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/z/zzz50e00/82918230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/c/zzc56e00/20262052...</td>\n",
       "      <td>Note</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/c/zzc56e00/20262052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/e/zze22c00/20852691...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/e/zze22c00/20852691...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf70d00/52522044...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf70d00/52522044...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/o/zzo50f00/00002373...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/o/zzo50f00/00002373...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/m/zzm98c00/88755863...</td>\n",
       "      <td>Scientific</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/m/zzm98c00/88755863...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/y/zzy82c00/20816290...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/y/zzy82c00/20816290...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>./SmallTobacco/imagesp/p/k/c/pkc78d00/50281308...</td>\n",
       "      <td>Report</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesp/p/k/c/pkc78d00/50281308...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf89d00/50027284...</td>\n",
       "      <td>Report</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf89d00/50027284...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw14f00/00000237...</td>\n",
       "      <td>News</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw14f00/00000237...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/r/zzr79d00/50040979...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/r/zzr79d00/50040979...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/g/zzg97c00/51760080...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/g/zzg97c00/51760080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/l/zzl02a00/10024022...</td>\n",
       "      <td>News</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/l/zzl02a00/10024022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/l/zzl34c00/83504123...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/l/zzl34c00/83504123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza39c00/25053983...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza39c00/25053983...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/z/zzz00c00/20851336...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/z/zzz00c00/20851336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/s/zzs81c00/20814220...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/s/zzs81c00/20814220...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/h/zzh43f00/00131654...</td>\n",
       "      <td>Scientific</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/h/zzh43f00/00131654...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3540</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/x/zzx23c00/98201361...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/x/zzx23c00/98201361...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/h/zzh40c00/ti112117...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/h/zzh40c00/ti112117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>./SmallTobacco/imagesi/i/n/m/inm1aa00/10031395...</td>\n",
       "      <td>News</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesi/i/n/m/inm1aa00/10031395...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>./SmallTobacco/imagesi/i/n/w/inw95d00/50479406...</td>\n",
       "      <td>Resume</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesi/i/n/w/inw95d00/50479406...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/m/zzm53d00/51098753...</td>\n",
       "      <td>Form</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/m/zzm53d00/51098753...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza79e00/20291484...</td>\n",
       "      <td>Form</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza79e00/20291484...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/c/zzc82d00/51803932...</td>\n",
       "      <td>Report</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/c/zzc82d00/51803932...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw92a00/51869580...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw92a00/51869580...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza65a00/53088691...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza65a00/53088691...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf68d00/50316513...</td>\n",
       "      <td>Report</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf68d00/50316513...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/e/zze88d00/50247442...</td>\n",
       "      <td>ADVE</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/e/zze88d00/50247442...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3551 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                img_dir       class label  \\\n",
       "0     ./SmallTobacco/imagesz/z/z/a/zza37d00/20734258...        Note     1   \n",
       "1     ./SmallTobacco/imagesz/z/z/r/zzr47c00/20722058...        Memo     1   \n",
       "2     ./SmallTobacco/imagesv/v/a/k/vak71f00/20160034...        News     1   \n",
       "3     ./SmallTobacco/imagesz/z/z/g/zzg93e00/20510443...        Memo     1   \n",
       "4     ./SmallTobacco/imagesz/z/z/j/zzj90e00/91985231...        Note     1   \n",
       "5     ./SmallTobacco/imagesz/z/z/f/zzf4aa00/10384492...        Note     1   \n",
       "6     ./SmallTobacco/imagesz/z/z/m/zzm72c00/20783394...       Email     1   \n",
       "7     ./SmallTobacco/imagesz/z/z/j/zzj8aa00/11019361...      Letter     1   \n",
       "8     ./SmallTobacco/imagesz/z/z/t/zzt65d00/50447313...      Letter     1   \n",
       "9     ./SmallTobacco/imagesz/z/z/c/zzc47d00/20703610...       Email     1   \n",
       "10    ./SmallTobacco/imagesz/z/z/w/zzw6aa00/50007953...      Letter     1   \n",
       "11    ./SmallTobacco/imagesz/z/z/q/zzq99c00/40044277...      Letter     1   \n",
       "12    ./SmallTobacco/imagesz/z/z/u/zzu40e00/03523378...        Memo     1   \n",
       "13    ./SmallTobacco/imagesz/z/z/n/zzn25e00/20286762...        Form     1   \n",
       "14     ./SmallTobacco/imagesz/z/z/b/zzb81d00/656421.png      Letter     1   \n",
       "15    ./SmallTobacco/imagesz/z/z/a/zza03a00/51861750...      Letter     1   \n",
       "16    ./SmallTobacco/imagesz/z/z/h/zzh28e00/10008165...        Memo     1   \n",
       "17    ./SmallTobacco/imagesz/z/z/u/zzu09e00/20506634...        Form     1   \n",
       "18    ./SmallTobacco/imagesz/z/z/p/zzp15c00/25054302...        Form     1   \n",
       "19    ./SmallTobacco/imagesz/z/z/j/zzj18d00/20478702...        News     1   \n",
       "20    ./SmallTobacco/imagesz/z/z/u/zzu37d00/20704226...        News     1   \n",
       "21    ./SmallTobacco/imagesz/z/z/p/zzp79c00/50224756...      Letter     1   \n",
       "22    ./SmallTobacco/imagesz/z/z/o/zzo38e00/10019069...        Memo     1   \n",
       "23    ./SmallTobacco/imagesz/z/z/x/zzx99d00/85651109...        Note     1   \n",
       "24    ./SmallTobacco/imagesz/z/z/w/zzw29d00/50187147...      Letter     1   \n",
       "25    ./SmallTobacco/imagesz/z/z/t/zzt12d00/71375081...        Form     1   \n",
       "26    ./SmallTobacco/imagesz/z/z/a/zza35e00/20250164...        ADVE     1   \n",
       "27    ./SmallTobacco/imagesz/z/z/b/zzb09d00/50426112...      Resume     1   \n",
       "28    ./SmallTobacco/imagesz/z/z/y/zzy20e00/92064329...        Memo     1   \n",
       "29    ./SmallTobacco/imagesz/z/z/v/zzv16e00/20546414...        Memo     1   \n",
       "...                                                 ...         ...   ...   \n",
       "3521  ./SmallTobacco/imagesz/z/z/y/zzy28d00/20717608...        Memo     1   \n",
       "3522  ./SmallTobacco/imagesz/z/z/z/zzz50e00/82918230...        Memo     1   \n",
       "3523  ./SmallTobacco/imagesz/z/z/c/zzc56e00/20262052...        Note     1   \n",
       "3524  ./SmallTobacco/imagesz/z/z/e/zze22c00/20852691...       Email     1   \n",
       "3525  ./SmallTobacco/imagesz/z/z/f/zzf70d00/52522044...       Email     1   \n",
       "3526  ./SmallTobacco/imagesz/z/z/o/zzo50f00/00002373...        Memo     1   \n",
       "3527  ./SmallTobacco/imagesz/z/z/m/zzm98c00/88755863...  Scientific     1   \n",
       "3528  ./SmallTobacco/imagesz/z/z/y/zzy82c00/20816290...       Email     1   \n",
       "3529  ./SmallTobacco/imagesp/p/k/c/pkc78d00/50281308...      Report     1   \n",
       "3530  ./SmallTobacco/imagesz/z/z/f/zzf89d00/50027284...      Report     1   \n",
       "3531  ./SmallTobacco/imagesz/z/z/w/zzw14f00/00000237...        News     1   \n",
       "3532  ./SmallTobacco/imagesz/z/z/r/zzr79d00/50040979...      Letter     1   \n",
       "3533  ./SmallTobacco/imagesz/z/z/g/zzg97c00/51760080...      Letter     1   \n",
       "3534  ./SmallTobacco/imagesz/z/z/l/zzl02a00/10024022...        News     1   \n",
       "3535  ./SmallTobacco/imagesz/z/z/l/zzl34c00/83504123...        Memo     1   \n",
       "3536  ./SmallTobacco/imagesz/z/z/a/zza39c00/25053983...       Email     1   \n",
       "3537  ./SmallTobacco/imagesz/z/z/z/zzz00c00/20851336...       Email     1   \n",
       "3538  ./SmallTobacco/imagesz/z/z/s/zzs81c00/20814220...       Email     1   \n",
       "3539  ./SmallTobacco/imagesz/z/z/h/zzh43f00/00131654...  Scientific     1   \n",
       "3540  ./SmallTobacco/imagesz/z/z/x/zzx23c00/98201361...        Memo     1   \n",
       "3541  ./SmallTobacco/imagesz/z/z/h/zzh40c00/ti112117...      Letter     1   \n",
       "3542  ./SmallTobacco/imagesi/i/n/m/inm1aa00/10031395...        News     1   \n",
       "3543  ./SmallTobacco/imagesi/i/n/w/inw95d00/50479406...      Resume     1   \n",
       "3544  ./SmallTobacco/imagesz/z/z/m/zzm53d00/51098753...        Form     1   \n",
       "3545  ./SmallTobacco/imagesz/z/z/a/zza79e00/20291484...        Form     1   \n",
       "3546  ./SmallTobacco/imagesz/z/z/c/zzc82d00/51803932...      Report     1   \n",
       "3547  ./SmallTobacco/imagesz/z/z/w/zzw92a00/51869580...      Letter     1   \n",
       "3548  ./SmallTobacco/imagesz/z/z/a/zza65a00/53088691...       Email     1   \n",
       "3549  ./SmallTobacco/imagesz/z/z/f/zzf68d00/50316513...      Report     1   \n",
       "3550  ./SmallTobacco/imagesz/z/z/e/zze88d00/50247442...        ADVE     1   \n",
       "\n",
       "                                                ocr_dir  \n",
       "0     ./SmallTobacco/imagesz/z/z/a/zza37d00/20734258...  \n",
       "1     ./SmallTobacco/imagesz/z/z/r/zzr47c00/20722058...  \n",
       "2     ./SmallTobacco/imagesv/v/a/k/vak71f00/20160034...  \n",
       "3     ./SmallTobacco/imagesz/z/z/g/zzg93e00/20510443...  \n",
       "4     ./SmallTobacco/imagesz/z/z/j/zzj90e00/91985231...  \n",
       "5     ./SmallTobacco/imagesz/z/z/f/zzf4aa00/10384492...  \n",
       "6     ./SmallTobacco/imagesz/z/z/m/zzm72c00/20783394...  \n",
       "7     ./SmallTobacco/imagesz/z/z/j/zzj8aa00/11019361...  \n",
       "8     ./SmallTobacco/imagesz/z/z/t/zzt65d00/50447313...  \n",
       "9     ./SmallTobacco/imagesz/z/z/c/zzc47d00/20703610...  \n",
       "10    ./SmallTobacco/imagesz/z/z/w/zzw6aa00/50007953...  \n",
       "11    ./SmallTobacco/imagesz/z/z/q/zzq99c00/40044277...  \n",
       "12    ./SmallTobacco/imagesz/z/z/u/zzu40e00/03523378...  \n",
       "13    ./SmallTobacco/imagesz/z/z/n/zzn25e00/20286762...  \n",
       "14     ./SmallTobacco/imagesz/z/z/b/zzb81d00/656421.txt  \n",
       "15    ./SmallTobacco/imagesz/z/z/a/zza03a00/51861750...  \n",
       "16    ./SmallTobacco/imagesz/z/z/h/zzh28e00/10008165...  \n",
       "17    ./SmallTobacco/imagesz/z/z/u/zzu09e00/20506634...  \n",
       "18    ./SmallTobacco/imagesz/z/z/p/zzp15c00/25054302...  \n",
       "19    ./SmallTobacco/imagesz/z/z/j/zzj18d00/20478702...  \n",
       "20    ./SmallTobacco/imagesz/z/z/u/zzu37d00/20704226...  \n",
       "21    ./SmallTobacco/imagesz/z/z/p/zzp79c00/50224756...  \n",
       "22    ./SmallTobacco/imagesz/z/z/o/zzo38e00/10019069...  \n",
       "23    ./SmallTobacco/imagesz/z/z/x/zzx99d00/85651109...  \n",
       "24    ./SmallTobacco/imagesz/z/z/w/zzw29d00/50187147...  \n",
       "25    ./SmallTobacco/imagesz/z/z/t/zzt12d00/71375081...  \n",
       "26    ./SmallTobacco/imagesz/z/z/a/zza35e00/20250164...  \n",
       "27    ./SmallTobacco/imagesz/z/z/b/zzb09d00/50426112...  \n",
       "28    ./SmallTobacco/imagesz/z/z/y/zzy20e00/92064329...  \n",
       "29    ./SmallTobacco/imagesz/z/z/v/zzv16e00/20546414...  \n",
       "...                                                 ...  \n",
       "3521  ./SmallTobacco/imagesz/z/z/y/zzy28d00/20717608...  \n",
       "3522  ./SmallTobacco/imagesz/z/z/z/zzz50e00/82918230...  \n",
       "3523  ./SmallTobacco/imagesz/z/z/c/zzc56e00/20262052...  \n",
       "3524  ./SmallTobacco/imagesz/z/z/e/zze22c00/20852691...  \n",
       "3525  ./SmallTobacco/imagesz/z/z/f/zzf70d00/52522044...  \n",
       "3526  ./SmallTobacco/imagesz/z/z/o/zzo50f00/00002373...  \n",
       "3527  ./SmallTobacco/imagesz/z/z/m/zzm98c00/88755863...  \n",
       "3528  ./SmallTobacco/imagesz/z/z/y/zzy82c00/20816290...  \n",
       "3529  ./SmallTobacco/imagesp/p/k/c/pkc78d00/50281308...  \n",
       "3530  ./SmallTobacco/imagesz/z/z/f/zzf89d00/50027284...  \n",
       "3531  ./SmallTobacco/imagesz/z/z/w/zzw14f00/00000237...  \n",
       "3532  ./SmallTobacco/imagesz/z/z/r/zzr79d00/50040979...  \n",
       "3533  ./SmallTobacco/imagesz/z/z/g/zzg97c00/51760080...  \n",
       "3534  ./SmallTobacco/imagesz/z/z/l/zzl02a00/10024022...  \n",
       "3535  ./SmallTobacco/imagesz/z/z/l/zzl34c00/83504123...  \n",
       "3536  ./SmallTobacco/imagesz/z/z/a/zza39c00/25053983...  \n",
       "3537  ./SmallTobacco/imagesz/z/z/z/zzz00c00/20851336...  \n",
       "3538  ./SmallTobacco/imagesz/z/z/s/zzs81c00/20814220...  \n",
       "3539  ./SmallTobacco/imagesz/z/z/h/zzh43f00/00131654...  \n",
       "3540  ./SmallTobacco/imagesz/z/z/x/zzx23c00/98201361...  \n",
       "3541  ./SmallTobacco/imagesz/z/z/h/zzh40c00/ti112117...  \n",
       "3542  ./SmallTobacco/imagesi/i/n/m/inm1aa00/10031395...  \n",
       "3543  ./SmallTobacco/imagesi/i/n/w/inw95d00/50479406...  \n",
       "3544  ./SmallTobacco/imagesz/z/z/m/zzm53d00/51098753...  \n",
       "3545  ./SmallTobacco/imagesz/z/z/a/zza79e00/20291484...  \n",
       "3546  ./SmallTobacco/imagesz/z/z/c/zzc82d00/51803932...  \n",
       "3547  ./SmallTobacco/imagesz/z/z/w/zzw92a00/51869580...  \n",
       "3548  ./SmallTobacco/imagesz/z/z/a/zza65a00/53088691...  \n",
       "3549  ./SmallTobacco/imagesz/z/z/f/zzf68d00/50316513...  \n",
       "3550  ./SmallTobacco/imagesz/z/z/e/zze88d00/50247442...  \n",
       "\n",
       "[3551 rows x 4 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "file_read = open('./Data/Small_Tobacco_cover.csv', \"rU\")\n",
    "reader = csv.reader(file_read, delimiter=',')\n",
    "df = []\n",
    "\n",
    "for element in reader:\n",
    "    clase = int(element[1])\n",
    "    if(clase == 0): \n",
    "        cat = 'Resume'\n",
    "    elif(clase == 1):\n",
    "        cat = 'News'\n",
    "    elif(clase == 2):\n",
    "        cat = 'Scientific'\n",
    "    elif(clase == 3):\n",
    "        cat = 'Email'\n",
    "    elif(clase == 4):\n",
    "        cat = 'ADVE'\n",
    "    elif(clase == 5):\n",
    "        cat = 'Memo'\n",
    "    elif(clase == 6):\n",
    "        cat = 'Report'\n",
    "    elif(clase == 7):\n",
    "        cat = 'Form'\n",
    "    elif(clase == 8):\n",
    "        cat = 'Note'\n",
    "    elif(clase == 9):\n",
    "        cat = 'Letter'\n",
    "    new_row = [element[0],cat, element[2],element[3]]\n",
    "    df.append(new_row)\n",
    "    \n",
    "file_read.close()\n",
    "\n",
    "print(reader)\n",
    "columns = ['img_dir','class', 'label', 'ocr_dir']\n",
    "df = pd.DataFrame(df, columns = columns)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_class = df['class']\n",
    "df_class = df_class.values\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.hist([s for s in df_class], bins=10)\n",
    "#label.set_horizontalalignment('right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = df.values\n",
    "test_sample = []\n",
    "train_sample = []\n",
    "test_samples = 0\n",
    "classes = ['Resume','News','Scientific','Email','ADVE','Memo','Report','Form','Note','Letter']\n",
    "for clas in classes:\n",
    "    counter = 0\n",
    "    for row in values:\n",
    "        if row[1] == clas and counter < 100:\n",
    "            counter += 1\n",
    "            new_row = [row[0], row[1], row[2], row[3]]\n",
    "            train_sample.append(new_row)\n",
    "            \n",
    "for row in values:\n",
    "    counter = 0\n",
    "    for element in train_sample:\n",
    "        if row[0] != element[0]:\n",
    "            counter += 1\n",
    "        if counter == len(train_sample):\n",
    "            new_row = [row[0], row[1], row[2], row[3]]\n",
    "            test_sample.append(new_row)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(test_sample)\n",
    "random.shuffle(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./SmallTobacco/imagesz/z/z/d/zzd40d00/518288917+-8918_0.png',\n",
       " 'Letter',\n",
       " '1',\n",
       " './SmallTobacco/imagesz/z/z/d/zzd40d00/518288917+-8918_0.txt']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample[0]\n",
    "#len(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2551"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bscuser/anaconda3/envs/dl/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: 'U' mode is deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "file_read = open('./Data/Small_Tobacco_cover.csv', \"rU\")\n",
    "reader = csv.reader(file_read, delimiter=',')\n",
    "\n",
    "df = []\n",
    "\n",
    "for element in reader:\n",
    "    new_row = [element[0],element[1], element[2],element[3]]\n",
    "    df.append(new_row)\n",
    "\n",
    "file_read.close()\n",
    "\n",
    "columns = ['img_dir','class', 'label', 'ocr_dir']\n",
    "df = pd.DataFrame(df, columns = columns)\n",
    "df = df.sample(frac=1).reset_index(drop=True) #shuffle\n",
    "\n",
    "values = df.values\n",
    "train_sample = []\n",
    "test_sample = []\n",
    "classes = ['0','1','2','3','4','5','6','7','8','9']\n",
    "for clas in classes:\n",
    "    counter = 0\n",
    "    for row in values:\n",
    "        if row[1] == clas and counter < 100:\n",
    "            counter += 1\n",
    "            new_row = [row[0], row[1], row[2], row[3]]\n",
    "            train_sample.append(new_row)\n",
    "            \n",
    "for row in values:\n",
    "    counter = 0\n",
    "    for element in train_sample:\n",
    "        if row[0] != element[0]:\n",
    "            counter += 1\n",
    "        if counter == len(train_sample):\n",
    "            new_row = [row[0], row[1], row[2], row[3]]\n",
    "            test_sample.append(new_row)\n",
    "import random\n",
    "random.shuffle(test_sample)\n",
    "random.shuffle(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original label csv reading into list\n",
    "addrs = []\n",
    "labels = []\n",
    "segmentation = []\n",
    "ocr_dirs = []\n",
    "for row in train_sample:\n",
    "      adress = row[0]\n",
    "      lab = int(row[1])\n",
    "      seg = int(row[2])\n",
    "      ocr = row[3]\n",
    "      #label = np.array(label).astype(int)\n",
    "      addrs.append(adress)\n",
    "      labels.append(lab)\n",
    "      segmentation.append(seg)\n",
    "      ocr_dirs.append(ocr)\n",
    "\n",
    "for row in test_sample:\n",
    "      adress = row[0]\n",
    "      lab = int(row[1])\n",
    "      seg = int(row[2])\n",
    "      ocr = row[3]\n",
    "      #label = np.array(label).astype(int)\n",
    "      addrs.append(adress)\n",
    "      labels.append(lab)\n",
    "      segmentation.append(seg)\n",
    "      ocr_dirs.append(ocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3551"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(addrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f6f4f78b6a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pytorch/vision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'densenet121'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'hub'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision', 'densenet121', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "feature_extracting = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "use_pretrained = True\n",
    "model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "set_parameter_requires_grad(model_ft, feature_extracting)\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier = nn.Linear(num_ftrs, 10)\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
