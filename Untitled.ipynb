{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, Sentence\n",
    "\n",
    "from flair.embeddings import FlairEmbeddings, ELMoEmbeddings, DocumentEmbeddings\n",
    "\n",
    "# init embedding\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "\n",
    "\n",
    "# create a sentence\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# embed words in sentence\n",
    "flair_embedding_forward.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings, Sentence\n",
    "\n",
    "# initialize the word embeddings\n",
    "#glove_embedding = WordEmbeddings('glove')\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "flair_embedding_backward = FlairEmbeddings('news-backward')\n",
    "\n",
    "# initialize the document embeddings, mode = mean\n",
    "document_embeddings = DocumentPoolEmbeddings([#glove_embedding,\n",
    "                                              flair_embedding_backward,\n",
    "                                              flair_embedding_forward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n",
      "Embedding model DocumentPoolEmbeddings(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create an example sentence\n",
    "sentence = Sentence('The grass is green . And the sky is blue .')\n",
    "\n",
    "# embed the sentence with our document embedding\n",
    "document_embeddings.embed(sentence)\n",
    "\n",
    "embedding_of_sentence = sentence.get_embedding()\n",
    "# now check out the embedded sentence.\n",
    "print(document_embeddings.embedding_length)\n",
    "print('Embedding model', document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Union\n",
    "import logging\n",
    "log = logging.getLogger(\"flair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary:\n",
    "    \"\"\"\n",
    "    This class holds a dictionary that maps strings to IDs, used to generate one-hot encodings of strings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, add_unk=True):\n",
    "        # init dictionaries\n",
    "        self.item2idx: Dict[str, int] = {}\n",
    "        self.idx2item: List[str] = []\n",
    "        self.multi_label: bool = False\n",
    "\n",
    "        # in order to deal with unknown tokens, add <unk>\n",
    "        if add_unk:\n",
    "            self.add_item(\"<unk>\")\n",
    "\n",
    "    def add_item(self, item: str) -> int:\n",
    "        \"\"\"\n",
    "        add string - if already in dictionary returns its ID. if not in dictionary, it will get a new ID.\n",
    "        :param item: a string for which to assign an id.\n",
    "        :return: ID of string\n",
    "        \"\"\"\n",
    "        item = item.encode(\"utf-8\")\n",
    "        if item not in self.item2idx:\n",
    "            self.idx2item.append(item)\n",
    "            self.item2idx[item] = len(self.idx2item) - 1\n",
    "        return self.item2idx[item]\n",
    "\n",
    "    def get_idx_for_item(self, item: str) -> int:\n",
    "        \"\"\"\n",
    "        returns the ID of the string, otherwise 0\n",
    "        :param item: string for which ID is requested\n",
    "        :return: ID of string, otherwise 0\n",
    "        \"\"\"\n",
    "        item = item.encode(\"utf-8\")\n",
    "        if item in self.item2idx.keys():\n",
    "            return self.item2idx[item]\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def get_items(self) -> List[str]:\n",
    "        items = []\n",
    "        for item in self.idx2item:\n",
    "            items.append(item.decode(\"UTF-8\"))\n",
    "        return items\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.idx2item)\n",
    "\n",
    "    def get_item_for_index(self, idx):\n",
    "        return self.idx2item[idx].decode(\"UTF-8\")\n",
    "\n",
    "    def save(self, savefile):\n",
    "        import pickle\n",
    "\n",
    "        with open(savefile, \"wb\") as f:\n",
    "            mappings = {\"idx2item\": self.idx2item, \"item2idx\": self.item2idx}\n",
    "            pickle.dump(mappings, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_file(cls, filename: str):\n",
    "        import pickle\n",
    "\n",
    "        dictionary: Dictionary = Dictionary()\n",
    "        with open(filename, \"rb\") as f:\n",
    "            mappings = pickle.load(f, encoding=\"latin1\")\n",
    "            idx2item = mappings[\"idx2item\"]\n",
    "            item2idx = mappings[\"item2idx\"]\n",
    "            dictionary.item2idx = item2idx\n",
    "            dictionary.idx2item = idx2item\n",
    "        return dictionary\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, name: str):\n",
    "        from flair.file_utils import cached_path\n",
    "\n",
    "        if name == \"chars\" or name == \"common-chars\":\n",
    "            base_path = \"https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models/common_characters\"\n",
    "            char_dict = cached_path(base_path, cache_dir=\"datasets\")\n",
    "            return Dictionary.load_from_file(char_dict)\n",
    "\n",
    "        return Dictionary.load_from_file(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.file_utils import Tqdm\n",
    "def make_label_dictionarya(self) -> Dictionary:\n",
    "        \"\"\"\n",
    "        Creates a dictionary of all labels assigned to the sentences in the corpus.\n",
    "        :return: dictionary of labels\n",
    "        \"\"\"\n",
    "        label_dictionary: Dictionary = Dictionary(add_unk=False)\n",
    "        label_dictionary.multi_label = False\n",
    "\n",
    "        from datasets import DataLoader\n",
    "\n",
    "        loader = DataLoader(self.train, batch_size=1)\n",
    "\n",
    "        log.info(\"Computing label dictionary. Progress:\")\n",
    "        for batch in Tqdm.tqdm(iter(loader)):\n",
    "\n",
    "            for sentence in batch:\n",
    " \n",
    "\n",
    "                for label in sentence.labels:\n",
    "                    label_dictionary.add_item(label.value)\n",
    "\n",
    "                if not label_dictionary.multi_label:\n",
    "                    if len(sentence.labels) > 1:\n",
    "                        label_dictionary.multi_label = True\n",
    "\n",
    "        log.info(label_dictionary.idx2item)\n",
    "\n",
    "        return label_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Corpus\n",
    "from datasets import ClassificationCorpus\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = './'\n",
    "\n",
    "# load corpus containing training, test and dev data\n",
    "corpus: Corpus = ClassificationCorpus(data_folder,\n",
    "                                      test_file='test.txt',\n",
    "                                      dev_file='dev.txt',\n",
    "                                      train_file='train.txt')\n",
    "\n",
    "\n",
    "# 2. create the label dictionary\n",
    "label_dict = make_label_dictionarya(corpus)\n",
    "print(get_label_distribution(corpus))\n",
    "\n",
    "# 3. make a list of word embeddings\n",
    "word_embeddings = [WordEmbeddings('glove'),\n",
    "\n",
    "                   # comment in flair embeddings for state-of-the-art results\n",
    "                   # FlairEmbeddings('news-forward'),\n",
    "                   # FlairEmbeddings('news-backward'),\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. initialize document embedding by passing list of word embeddings\n",
    "# Can choose between many RNN types (GRU by default, to change use rnn_type parameter)\n",
    "document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,\n",
    "                                                                     hidden_size=512,\n",
    "                                                                     reproject_words=True,\n",
    "                                                                     reproject_words_dimension=256,\n",
    "                                                                     )\n",
    "\n",
    "# 5. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
    "\n",
    "# 6. initialize the text classifier trainer\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "# 7. start the training\n",
    "trainer.train('resources/taggers/ag_news',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              anneal_factor=0.5,\n",
    "              patience=5,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import FlairEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "# init embedding\n",
    "flair_embedding_forward = FlairEmbeddings(model = 'news-forward')\n",
    "\n",
    "print('pt loaded')\n",
    "\n",
    "# create a sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# embed words in sentence\n",
    "flair_embedding_forward.embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    token_embedding = token.embedding\n",
    "    print(token_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding = ELMoEmbeddings('small')\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "\n",
    "sentence = Sentence('the grass is green .')\n",
    "\n",
    "glove_embedding.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in sentence:\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a sentence. This is another sentence.\"\n",
    "\n",
    "from segtok.segmenter import split_single\n",
    "#sentences = [Sentence(sent, use_tokenizer=True) for sent in split_single(text)]\n",
    "sentences = [sent for sent in split_single(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_embedding_forward.embed(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indiv_sentence in sentences:\n",
    "    for token in indiv_sentence:\n",
    "        print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "words = []\n",
    "idx = 0\n",
    "word2idx = {}\n",
    "vectors = bcolz.carray(np.zeros(1), rootdir=f'./Data/6B.100.dat', mode='w')\n",
    "\n",
    "with open(f'./Data/glove.6B.100d.txt', 'rb') as f:\n",
    "    for l in f:\n",
    "        line = l.decode().split()\n",
    "        word = line[0]\n",
    "        words.append(word)\n",
    "        word2idx[word] = idx\n",
    "        idx += 1\n",
    "        vect = np.array(line[1:]).astype(np.float)\n",
    "        vectors.append(vect)\n",
    "    \n",
    "vectors = bcolz.carray(vectors[1:].reshape((400000, 100)), rootdir=f'./Data/6B.100.dat', mode='w')\n",
    "vectors.flush()\n",
    "pickle.dump(words, open(f'./Data/6B.100_words.pkl', 'wb'))\n",
    "pickle.dump(word2idx, open(f'./Data/6B.100_idx.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = bcolz.open(f'./Data/6B.100.dat')[:]\n",
    "words = pickle.load(open(f'./Data/6B.100_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open(f'./Data/6B.100_idx.pkl', 'rb'))\n",
    "\n",
    "glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segtok.tokenizer import split_contractions\n",
    "from segtok.tokenizer import word_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from itertools import *\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "hdf5_file='./HDF5_files/hdf5_10.hdf5'\n",
    "h5_file = h5py.File(hdf5_file, \"r\")\n",
    "ocr = h5_file.get('train_ocrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_full = []\n",
    "for counter, text in enumerate(ocr):\n",
    "    contractions = split_contractions(word_tokenizer(text))\n",
    "    for element in contractions:\n",
    "        element = element.lower()\n",
    "        contractions_full.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contractions_full)\n",
    "target_vocab = contractions_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim =100\n",
    "matrix_len = len(target_vocab)\n",
    "print(matrix_len)\n",
    "weights_matrix = np.zeros((matrix_len, 100))\n",
    "words_found = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word in enumerate(target_vocab):\n",
    "    try: \n",
    "        weights_matrix[i] = glove[word]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.size()\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenetv3 import mobilenetv3_large, mobilenetv3_small\n",
    "\n",
    "net_large = mobilenetv3_large()\n",
    "\n",
    "net_large.load_state_dict(torch.load('./pretrained/mobilenetv3-large-657e7b3d.pth',map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.imagenet import mobilenetv2\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mobilenetv2()\n",
    "net.load_state_dict(torch.load('pretrained/mobilenetv2_1.0-0c6065bc.pth', map_location='cpu'))\n",
    "feature_extracting = True\n",
    "set_parameter_requires_grad(net, feature_extracting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.classifier = nn.Linear(1280, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extracting:\n",
    "    params_to_update = []\n",
    "    for name,param in net.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in net.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_model):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        #self.args = args\n",
    "        \n",
    "        #V = args.embed_num\n",
    "        D = 2048 #embed_dim, 4196 for doc_embeddings\n",
    "        C = 10 #class_num\n",
    "        Ci = 1\n",
    "        Co = 100 #kernel_num -> number of kernel with the same size\n",
    "        Ks = [3,4,5] #kernel_sizes -> size = number of words\n",
    "\n",
    "        #self.embed = nn.Embedding(V, D)\n",
    "        # self.convs1 = [nn.Conv2d(Ci, Co, (K, D)) for K in Ks]\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        self.conv13 = nn.Conv2d(Ci, Co, (3, D))\n",
    "        self.conv14 = nn.Conv2d(Ci, Co, (4, D))\n",
    "        self.conv15 = nn.Conv2d(Ci, Co, (5, D))\n",
    "        '''\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "        \n",
    "        self.image_model = image_model\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        \n",
    "        #Output will be size (1,Ks*Co) -> Maxpool will get one ĉ value =  max(c_1,c_2...), where c_i is\n",
    "        #the result of the convolution operation of the kernel over the input\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "    def forward(self, x, x2):\n",
    "        #x = self.embed(x)  # (N, W, D)\n",
    "        \n",
    "        #if self.args.static:\n",
    "            #x = Variable(x)\n",
    "        #print('CNN Text entry',x.shape)\n",
    "\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "        #print('unsqueeze',x.shape)\n",
    "        \n",
    "        \n",
    "        #print(x.shape)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
    "        \n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "        \n",
    "\n",
    "        x = torch.cat(x, 1) #[1,100] + [1,100] + [1,100] = [1,300]\n",
    "        \n",
    "        #print('After cat', x.shape)\n",
    "\n",
    "        '''\n",
    "        x1 = self.conv_and_pool(x,self.conv13) #(N,Co)\n",
    "        x2 = self.conv_and_pool(x,self.conv14) #(N,Co)\n",
    "        x3 = self.conv_and_pool(x,self.conv15) #(N,Co)\n",
    "        x = torch.cat((x1, x2, x3), 1) # (N,len(Ks)*Co)\n",
    "        '''\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        \n",
    "        x2 = self.image_model(x2)\n",
    "        \n",
    "        x2 = torch.cat((x,x2),1)\n",
    "        \n",
    "        \n",
    "        logit = x2\n",
    "        #logit = self.fc1(x)  # (N, C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = CNN_Text(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './resources/combined'\n",
    "flair_embedding_forward = FlairEmbeddings('./Data/news-forward-0.4.1.pt')\n",
    "\n",
    "# Dataset creation with image directory, image -> 'RGB' -> transformed to Mobilenetv2 input, Ocr,\n",
    "# Class and Segmentation\n",
    "__all__ = ['MobileNetV2', 'mobilenetv2_19']\n",
    "\n",
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.RandomCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])}\n",
    "#Independent train and test transformations can be done\n",
    "h5_dataset = H5Dataset(path='./HDF5_files/hdf5_small_tobacco_cover.hdf5', data_transforms=data_transforms['train'], embedding_model = flair_embedding_forward, phase = 'train')\n",
    "\n",
    "dataloader_train = DataLoader(h5_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "# for x in dataloader:\n",
    "#     x = x.to('cuda', non_blocking=True)\n",
    "\n",
    "#https://github.com/d-li14/mobilenetv2.pytorch\n",
    "net = mobilenetv2()\n",
    "net.load_state_dict(torch.load('pretrained/mobilenetv2_1.0-0c6065bc.pth'))\n",
    "feature_extracting = True\n",
    "set_parameter_requires_grad(net, feature_extracting)\n",
    "net.classifier = nn.Linear(1280, 300)\n",
    "\n",
    "# get model\n",
    "model = CNN_Text(net)\n",
    "#print(model)\n",
    "# define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# set optimize\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.00004)\n",
    "\n",
    "max_epochs = 1\n",
    "optimizer = optimizer_ft\n",
    "batch_size=1\n",
    "running_loss = 0.0\n",
    "loss_values = []\n",
    "epoch_values = []\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    running_loss = 0\n",
    "    steps = 0\n",
    "    # Training\n",
    "    print('Antes del loop')\n",
    "    for local_batch in dataloader_train:\n",
    "        image, ocr_text, labels = Variable(local_batch['image']), Variable(local_batch['ocr']), Variable(local_batch['class'])\n",
    "        #print(ocr_text.shape)\n",
    "        steps += 1\n",
    "        if ocr_text.shape[1]< 5:\n",
    "            print(steps)\n",
    "            pass\n",
    "        else:\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            #print(local_batch['image_dir'])\n",
    "\n",
    "            # forward\n",
    "            outputs = model(ocr_text, image)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            #print(preds, labels.long())\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            #print(outputs)\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #running_loss += loss.data[0]\n",
    "            if steps % 100 == 0:\n",
    "                print(steps)\n",
    "                #save(model,'./snapshot/', 'model', steps)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    #print(outputs)\n",
    "    print('[Epoch {}/{}], loss {}'.format(\n",
    "                    epoch, max_epochs,running_loss/800))\n",
    "\n",
    "    loss_values.append(running_loss/800)\n",
    "    epoch_values.append(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tobaco3482 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x7f47c2db5208>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bscuser/anaconda3/envs/dl/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: 'U' mode is deprecated\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_dir</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>ocr_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf14d00/50792073...</td>\n",
       "      <td>Form</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf14d00/50792073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza81f00/20250286...</td>\n",
       "      <td>News</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza81f00/20250286...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/g/zzg02a00/20263748...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/g/zzg02a00/20263748...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/y/zzy05d00/50568895...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/y/zzy05d00/50568895...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw20e00/89282835...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw20e00/89282835...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/k/zzk44e00/20221810...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/k/zzk44e00/20221810...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/x/zzx30c00/ti063906...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/x/zzx30c00/ti063906...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/p/zzp05a00/53023762...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/p/zzp05a00/53023762...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza19d00/50241753...</td>\n",
       "      <td>Report</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/a/zza19d00/50241753...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/p/zzp14d00/50777881...</td>\n",
       "      <td>Report</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/p/zzp14d00/50777881...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/t/zzt94d00/50582896...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/t/zzt94d00/50582896...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/v/zzv23e00/20255625...</td>\n",
       "      <td>Scientific</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/v/zzv23e00/20255625...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/c/zzc13d00/51434342...</td>\n",
       "      <td>Form</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/c/zzc13d00/51434342...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/v/zzv94d00/50581595...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/v/zzv94d00/50581595...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/o/zzo5aa00/11277226...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/o/zzo5aa00/11277226...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/c/zzc85c00/20769588...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/c/zzc85c00/20769588...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>./SmallTobacco/imagesp/p/k/u/pku01e00/87063899...</td>\n",
       "      <td>ADVE</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesp/p/k/u/pku01e00/87063899...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/z/zzz02e00/20228190...</td>\n",
       "      <td>Form</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/z/zzz02e00/20228190...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/n/zzn62e00/20601679...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/n/zzn62e00/20601679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/s/zzs02c00/20851039...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/s/zzs02c00/20851039...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/v/zzv79e00/00001935...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/v/zzv79e00/00001935...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf78d00/50279021...</td>\n",
       "      <td>Report</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf78d00/50279021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/m/zzm11c00/71360042...</td>\n",
       "      <td>Form</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/m/zzm11c00/71360042...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/b/zzb70d00/52250249...</td>\n",
       "      <td>Form</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/b/zzb70d00/52250249...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/u/zzu72c00/20784541...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/u/zzu72c00/20784541...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/h/zzh95e00/20264021...</td>\n",
       "      <td>Scientific</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/h/zzh95e00/20264021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/y/zzy19c00/20748241...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/y/zzy19c00/20748241...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/y/zzy20e00/92064329...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/y/zzy20e00/92064329...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/h/zzh28e00/10008165...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/h/zzh28e00/10008165...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/y/zzy95c00/20725689...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/y/zzy95c00/20725689...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw71e00/01142172...</td>\n",
       "      <td>Scientific</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw71e00/01142172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/i/zzi40c00/ti114919...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/i/zzi40c00/ti114919...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>./SmallTobacco/imagesi/i/n/k/ink09d00/50442704...</td>\n",
       "      <td>Resume</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesi/i/n/k/ink09d00/50442704...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/s/zzs00a00/60024487...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/s/zzs00a00/60024487...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/n/zzn86e00/20573620...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/n/zzn86e00/20573620...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3457</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/m/zzm80c00/20642070...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/m/zzm80c00/20642070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3458</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/h/zzh71e00/03662678...</td>\n",
       "      <td>Note</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/h/zzh71e00/03662678...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf15a00/52880794...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf15a00/52880794...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/q/zzq62c00/20776193...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/q/zzq62c00/20776193...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>./SmallTobacco/imagesi/i/n/q/inq39e00/25012048...</td>\n",
       "      <td>News</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesi/i/n/q/inq39e00/25012048...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/c/zzc55c00/20760127...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/c/zzc55c00/20760127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/o/zzo72c00/20783469...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/o/zzo72c00/20783469...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/n/zzn83c00/20455182...</td>\n",
       "      <td>Note</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/n/zzn83c00/20455182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/e/zze51c00/52317047...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/e/zze51c00/52317047...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/u/zzu76d00/ti165703...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/u/zzu76d00/ti165703...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/l/zzl41c00/20857637...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/l/zzl41c00/20857637...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/q/zzq74c00/87452548...</td>\n",
       "      <td>Form</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/q/zzq74c00/87452548...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/j/zzj05a00/20746780...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/j/zzj05a00/20746780...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/v/zzv72c00/20786264...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/v/zzv72c00/20786264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/q/zzq60e00/92707788...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/q/zzq60e00/92707788...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw98d00/50416058...</td>\n",
       "      <td>Scientific</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw98d00/50416058...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/r/zzr34a00/20673113...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/r/zzr34a00/20673113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/b/zzb67c00/20734539...</td>\n",
       "      <td>Memo</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/b/zzb67c00/20734539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/p/zzp67c00/20778520...</td>\n",
       "      <td>Form</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/p/zzp67c00/20778520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3476</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf92a00/52054682...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/f/zzf92a00/52054682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/j/zzj07d00/tnwl0035...</td>\n",
       "      <td>Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/j/zzj07d00/tnwl0035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw97c00/52779325...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/w/zzw97c00/52779325...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3479</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/q/zzq20c00/20808290...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/q/zzq20c00/20808290...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/z/zzz53e00/20301626...</td>\n",
       "      <td>Form</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/z/zzz53e00/20301626...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>./SmallTobacco/imagesz/z/z/l/zzl94a00/20697514...</td>\n",
       "      <td>Email</td>\n",
       "      <td>1</td>\n",
       "      <td>./SmallTobacco/imagesz/z/z/l/zzl94a00/20697514...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3482 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                img_dir       class label  \\\n",
       "0     ./SmallTobacco/imagesz/z/z/f/zzf14d00/50792073...        Form     1   \n",
       "1     ./SmallTobacco/imagesz/z/z/a/zza81f00/20250286...        News     1   \n",
       "2     ./SmallTobacco/imagesz/z/z/g/zzg02a00/20263748...        Memo     1   \n",
       "3     ./SmallTobacco/imagesz/z/z/y/zzy05d00/50568895...      Letter     1   \n",
       "4     ./SmallTobacco/imagesz/z/z/w/zzw20e00/89282835...        Memo     1   \n",
       "5     ./SmallTobacco/imagesz/z/z/k/zzk44e00/20221810...        Memo     1   \n",
       "6     ./SmallTobacco/imagesz/z/z/x/zzx30c00/ti063906...      Letter     1   \n",
       "7     ./SmallTobacco/imagesz/z/z/p/zzp05a00/53023762...       Email     1   \n",
       "8     ./SmallTobacco/imagesz/z/z/a/zza19d00/50241753...      Report     1   \n",
       "9     ./SmallTobacco/imagesz/z/z/p/zzp14d00/50777881...      Report     1   \n",
       "10    ./SmallTobacco/imagesz/z/z/t/zzt94d00/50582896...      Letter     1   \n",
       "11    ./SmallTobacco/imagesz/z/z/v/zzv23e00/20255625...  Scientific     1   \n",
       "12    ./SmallTobacco/imagesz/z/z/c/zzc13d00/51434342...        Form     1   \n",
       "13    ./SmallTobacco/imagesz/z/z/v/zzv94d00/50581595...      Letter     1   \n",
       "14    ./SmallTobacco/imagesz/z/z/o/zzo5aa00/11277226...      Letter     1   \n",
       "15    ./SmallTobacco/imagesz/z/z/c/zzc85c00/20769588...       Email     1   \n",
       "16    ./SmallTobacco/imagesp/p/k/u/pku01e00/87063899...        ADVE     1   \n",
       "17    ./SmallTobacco/imagesz/z/z/z/zzz02e00/20228190...        Form     1   \n",
       "18    ./SmallTobacco/imagesz/z/z/n/zzn62e00/20601679...        Memo     1   \n",
       "19    ./SmallTobacco/imagesz/z/z/s/zzs02c00/20851039...       Email     1   \n",
       "20    ./SmallTobacco/imagesz/z/z/v/zzv79e00/00001935...        Memo     1   \n",
       "21    ./SmallTobacco/imagesz/z/z/f/zzf78d00/50279021...      Report     1   \n",
       "22    ./SmallTobacco/imagesz/z/z/m/zzm11c00/71360042...        Form     1   \n",
       "23    ./SmallTobacco/imagesz/z/z/b/zzb70d00/52250249...        Form     1   \n",
       "24    ./SmallTobacco/imagesz/z/z/u/zzu72c00/20784541...       Email     1   \n",
       "25    ./SmallTobacco/imagesz/z/z/h/zzh95e00/20264021...  Scientific     1   \n",
       "26    ./SmallTobacco/imagesz/z/z/y/zzy19c00/20748241...       Email     1   \n",
       "27    ./SmallTobacco/imagesz/z/z/y/zzy20e00/92064329...        Memo     1   \n",
       "28    ./SmallTobacco/imagesz/z/z/h/zzh28e00/10008165...        Memo     1   \n",
       "29    ./SmallTobacco/imagesz/z/z/y/zzy95c00/20725689...       Email     1   \n",
       "...                                                 ...         ...   ...   \n",
       "3452  ./SmallTobacco/imagesz/z/z/w/zzw71e00/01142172...  Scientific     1   \n",
       "3453  ./SmallTobacco/imagesz/z/z/i/zzi40c00/ti114919...      Letter     1   \n",
       "3454  ./SmallTobacco/imagesi/i/n/k/ink09d00/50442704...      Resume     1   \n",
       "3455  ./SmallTobacco/imagesz/z/z/s/zzs00a00/60024487...      Letter     1   \n",
       "3456  ./SmallTobacco/imagesz/z/z/n/zzn86e00/20573620...        Memo     1   \n",
       "3457  ./SmallTobacco/imagesz/z/z/m/zzm80c00/20642070...       Email     1   \n",
       "3458  ./SmallTobacco/imagesz/z/z/h/zzh71e00/03662678...        Note     1   \n",
       "3459  ./SmallTobacco/imagesz/z/z/f/zzf15a00/52880794...       Email     1   \n",
       "3460  ./SmallTobacco/imagesz/z/z/q/zzq62c00/20776193...       Email     1   \n",
       "3461  ./SmallTobacco/imagesi/i/n/q/inq39e00/25012048...        News     1   \n",
       "3462  ./SmallTobacco/imagesz/z/z/c/zzc55c00/20760127...       Email     1   \n",
       "3463  ./SmallTobacco/imagesz/z/z/o/zzo72c00/20783469...       Email     1   \n",
       "3464  ./SmallTobacco/imagesz/z/z/n/zzn83c00/20455182...        Note     1   \n",
       "3465  ./SmallTobacco/imagesz/z/z/e/zze51c00/52317047...      Letter     1   \n",
       "3466  ./SmallTobacco/imagesz/z/z/u/zzu76d00/ti165703...      Letter     1   \n",
       "3467  ./SmallTobacco/imagesz/z/z/l/zzl41c00/20857637...       Email     1   \n",
       "3468  ./SmallTobacco/imagesz/z/z/q/zzq74c00/87452548...        Form     1   \n",
       "3469  ./SmallTobacco/imagesz/z/z/j/zzj05a00/20746780...       Email     1   \n",
       "3470  ./SmallTobacco/imagesz/z/z/v/zzv72c00/20786264...       Email     1   \n",
       "3471  ./SmallTobacco/imagesz/z/z/q/zzq60e00/92707788...        Memo     1   \n",
       "3472  ./SmallTobacco/imagesz/z/z/w/zzw98d00/50416058...  Scientific     1   \n",
       "3473  ./SmallTobacco/imagesz/z/z/r/zzr34a00/20673113...       Email     1   \n",
       "3474  ./SmallTobacco/imagesz/z/z/b/zzb67c00/20734539...        Memo     1   \n",
       "3475  ./SmallTobacco/imagesz/z/z/p/zzp67c00/20778520...        Form     1   \n",
       "3476  ./SmallTobacco/imagesz/z/z/f/zzf92a00/52054682...      Letter     1   \n",
       "3477  ./SmallTobacco/imagesz/z/z/j/zzj07d00/tnwl0035...      Letter     1   \n",
       "3478  ./SmallTobacco/imagesz/z/z/w/zzw97c00/52779325...       Email     1   \n",
       "3479  ./SmallTobacco/imagesz/z/z/q/zzq20c00/20808290...       Email     1   \n",
       "3480  ./SmallTobacco/imagesz/z/z/z/zzz53e00/20301626...        Form     1   \n",
       "3481  ./SmallTobacco/imagesz/z/z/l/zzl94a00/20697514...       Email     1   \n",
       "\n",
       "                                                ocr_dir  \n",
       "0     ./SmallTobacco/imagesz/z/z/f/zzf14d00/50792073...  \n",
       "1     ./SmallTobacco/imagesz/z/z/a/zza81f00/20250286...  \n",
       "2     ./SmallTobacco/imagesz/z/z/g/zzg02a00/20263748...  \n",
       "3     ./SmallTobacco/imagesz/z/z/y/zzy05d00/50568895...  \n",
       "4     ./SmallTobacco/imagesz/z/z/w/zzw20e00/89282835...  \n",
       "5     ./SmallTobacco/imagesz/z/z/k/zzk44e00/20221810...  \n",
       "6     ./SmallTobacco/imagesz/z/z/x/zzx30c00/ti063906...  \n",
       "7     ./SmallTobacco/imagesz/z/z/p/zzp05a00/53023762...  \n",
       "8     ./SmallTobacco/imagesz/z/z/a/zza19d00/50241753...  \n",
       "9     ./SmallTobacco/imagesz/z/z/p/zzp14d00/50777881...  \n",
       "10    ./SmallTobacco/imagesz/z/z/t/zzt94d00/50582896...  \n",
       "11    ./SmallTobacco/imagesz/z/z/v/zzv23e00/20255625...  \n",
       "12    ./SmallTobacco/imagesz/z/z/c/zzc13d00/51434342...  \n",
       "13    ./SmallTobacco/imagesz/z/z/v/zzv94d00/50581595...  \n",
       "14    ./SmallTobacco/imagesz/z/z/o/zzo5aa00/11277226...  \n",
       "15    ./SmallTobacco/imagesz/z/z/c/zzc85c00/20769588...  \n",
       "16    ./SmallTobacco/imagesp/p/k/u/pku01e00/87063899...  \n",
       "17    ./SmallTobacco/imagesz/z/z/z/zzz02e00/20228190...  \n",
       "18    ./SmallTobacco/imagesz/z/z/n/zzn62e00/20601679...  \n",
       "19    ./SmallTobacco/imagesz/z/z/s/zzs02c00/20851039...  \n",
       "20    ./SmallTobacco/imagesz/z/z/v/zzv79e00/00001935...  \n",
       "21    ./SmallTobacco/imagesz/z/z/f/zzf78d00/50279021...  \n",
       "22    ./SmallTobacco/imagesz/z/z/m/zzm11c00/71360042...  \n",
       "23    ./SmallTobacco/imagesz/z/z/b/zzb70d00/52250249...  \n",
       "24    ./SmallTobacco/imagesz/z/z/u/zzu72c00/20784541...  \n",
       "25    ./SmallTobacco/imagesz/z/z/h/zzh95e00/20264021...  \n",
       "26    ./SmallTobacco/imagesz/z/z/y/zzy19c00/20748241...  \n",
       "27    ./SmallTobacco/imagesz/z/z/y/zzy20e00/92064329...  \n",
       "28    ./SmallTobacco/imagesz/z/z/h/zzh28e00/10008165...  \n",
       "29    ./SmallTobacco/imagesz/z/z/y/zzy95c00/20725689...  \n",
       "...                                                 ...  \n",
       "3452  ./SmallTobacco/imagesz/z/z/w/zzw71e00/01142172...  \n",
       "3453  ./SmallTobacco/imagesz/z/z/i/zzi40c00/ti114919...  \n",
       "3454  ./SmallTobacco/imagesi/i/n/k/ink09d00/50442704...  \n",
       "3455  ./SmallTobacco/imagesz/z/z/s/zzs00a00/60024487...  \n",
       "3456  ./SmallTobacco/imagesz/z/z/n/zzn86e00/20573620...  \n",
       "3457  ./SmallTobacco/imagesz/z/z/m/zzm80c00/20642070...  \n",
       "3458  ./SmallTobacco/imagesz/z/z/h/zzh71e00/03662678...  \n",
       "3459  ./SmallTobacco/imagesz/z/z/f/zzf15a00/52880794...  \n",
       "3460  ./SmallTobacco/imagesz/z/z/q/zzq62c00/20776193...  \n",
       "3461  ./SmallTobacco/imagesi/i/n/q/inq39e00/25012048...  \n",
       "3462  ./SmallTobacco/imagesz/z/z/c/zzc55c00/20760127...  \n",
       "3463  ./SmallTobacco/imagesz/z/z/o/zzo72c00/20783469...  \n",
       "3464  ./SmallTobacco/imagesz/z/z/n/zzn83c00/20455182...  \n",
       "3465  ./SmallTobacco/imagesz/z/z/e/zze51c00/52317047...  \n",
       "3466  ./SmallTobacco/imagesz/z/z/u/zzu76d00/ti165703...  \n",
       "3467  ./SmallTobacco/imagesz/z/z/l/zzl41c00/20857637...  \n",
       "3468  ./SmallTobacco/imagesz/z/z/q/zzq74c00/87452548...  \n",
       "3469  ./SmallTobacco/imagesz/z/z/j/zzj05a00/20746780...  \n",
       "3470  ./SmallTobacco/imagesz/z/z/v/zzv72c00/20786264...  \n",
       "3471  ./SmallTobacco/imagesz/z/z/q/zzq60e00/92707788...  \n",
       "3472  ./SmallTobacco/imagesz/z/z/w/zzw98d00/50416058...  \n",
       "3473  ./SmallTobacco/imagesz/z/z/r/zzr34a00/20673113...  \n",
       "3474  ./SmallTobacco/imagesz/z/z/b/zzb67c00/20734539...  \n",
       "3475  ./SmallTobacco/imagesz/z/z/p/zzp67c00/20778520...  \n",
       "3476  ./SmallTobacco/imagesz/z/z/f/zzf92a00/52054682...  \n",
       "3477  ./SmallTobacco/imagesz/z/z/j/zzj07d00/tnwl0035...  \n",
       "3478  ./SmallTobacco/imagesz/z/z/w/zzw97c00/52779325...  \n",
       "3479  ./SmallTobacco/imagesz/z/z/q/zzq20c00/20808290...  \n",
       "3480  ./SmallTobacco/imagesz/z/z/z/zzz53e00/20301626...  \n",
       "3481  ./SmallTobacco/imagesz/z/z/l/zzl94a00/20697514...  \n",
       "\n",
       "[3482 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "file_read = open('./Data/Small_Tobacco_cover_final.csv', \"rU\")\n",
    "reader = csv.reader(file_read, delimiter=',')\n",
    "df = []\n",
    "\n",
    "for element in reader:\n",
    "    clase = int(element[1])\n",
    "    if(clase == 0): \n",
    "        cat = 'Resume'\n",
    "    elif(clase == 1):\n",
    "        cat = 'News'\n",
    "    elif(clase == 2):\n",
    "        cat = 'Scientific'\n",
    "    elif(clase == 3):\n",
    "        cat = 'Email'\n",
    "    elif(clase == 4):\n",
    "        cat = 'ADVE'\n",
    "    elif(clase == 5):\n",
    "        cat = 'Memo'\n",
    "    elif(clase == 6):\n",
    "        cat = 'Report'\n",
    "    elif(clase == 7):\n",
    "        cat = 'Form'\n",
    "    elif(clase == 8):\n",
    "        cat = 'Note'\n",
    "    elif(clase == 9):\n",
    "        cat = 'Letter'\n",
    "    new_row = [element[0],cat, element[2],element[3]]\n",
    "    df.append(new_row)\n",
    "    \n",
    "file_read.close()\n",
    "\n",
    "print(reader)\n",
    "columns = ['img_dir','class', 'label', 'ocr_dir']\n",
    "df = pd.DataFrame(df, columns = columns)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use(\"ggplot\")\n",
    "\n",
    "df_class = df['class']\n",
    "df_class = df_class.values\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.hist([s for s in df_class], bins=10, color = \"dodgerblue\", lw=2, ec=\"white\")\n",
    "#label.set_horizontalalignment('right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = df.values\n",
    "test_sample = []\n",
    "train_sample = []\n",
    "test_samples = 0\n",
    "classes = ['Resume','News','Scientific','Email','ADVE','Memo','Report','Form','Note','Letter']\n",
    "for clas in classes:\n",
    "    counter = 0\n",
    "    for row in values:\n",
    "        if row[1] == clas and counter < 100:\n",
    "            counter += 1\n",
    "            new_row = [row[0], row[1], row[2], row[3]]\n",
    "            train_sample.append(new_row)\n",
    "            \n",
    "for row in values:\n",
    "    counter = 0\n",
    "    for element in train_sample:\n",
    "        if row[0] != element[0]:\n",
    "            counter += 1\n",
    "        if counter == len(train_sample):\n",
    "            new_row = [row[0], row[1], row[2], row[3]]\n",
    "            test_sample.append(new_row)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(test_sample)\n",
    "random.shuffle(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./SmallTobacco/imagesz/z/z/d/zzd40d00/518288917+-8918_0.png',\n",
       " 'Letter',\n",
       " '1',\n",
       " './SmallTobacco/imagesz/z/z/d/zzd40d00/518288917+-8918_0.txt']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample[0]\n",
    "#len(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2551"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bscuser/anaconda3/envs/dl/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: 'U' mode is deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "file_read = open('./Data/Small_Tobacco_cover.csv', \"rU\")\n",
    "reader = csv.reader(file_read, delimiter=',')\n",
    "\n",
    "df = []\n",
    "\n",
    "for element in reader:\n",
    "    new_row = [element[0],element[1], element[2],element[3]]\n",
    "    df.append(new_row)\n",
    "\n",
    "file_read.close()\n",
    "\n",
    "columns = ['img_dir','class', 'label', 'ocr_dir']\n",
    "df = pd.DataFrame(df, columns = columns)\n",
    "df = df.sample(frac=1).reset_index(drop=True) #shuffle\n",
    "\n",
    "values = df.values\n",
    "train_sample = []\n",
    "test_sample = []\n",
    "classes = ['0','1','2','3','4','5','6','7','8','9']\n",
    "for clas in classes:\n",
    "    counter = 0\n",
    "    for row in values:\n",
    "        if row[1] == clas and counter < 100:\n",
    "            counter += 1\n",
    "            new_row = [row[0], row[1], row[2], row[3]]\n",
    "            train_sample.append(new_row)\n",
    "            \n",
    "for row in values:\n",
    "    counter = 0\n",
    "    for element in train_sample:\n",
    "        if row[0] != element[0]:\n",
    "            counter += 1\n",
    "        if counter == len(train_sample):\n",
    "            new_row = [row[0], row[1], row[2], row[3]]\n",
    "            test_sample.append(new_row)\n",
    "import random\n",
    "random.shuffle(test_sample)\n",
    "random.shuffle(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original label csv reading into list\n",
    "addrs = []\n",
    "labels = []\n",
    "segmentation = []\n",
    "ocr_dirs = []\n",
    "for row in train_sample:\n",
    "      adress = row[0]\n",
    "      lab = int(row[1])\n",
    "      seg = int(row[2])\n",
    "      ocr = row[3]\n",
    "      #label = np.array(label).astype(int)\n",
    "      addrs.append(adress)\n",
    "      labels.append(lab)\n",
    "      segmentation.append(seg)\n",
    "      ocr_dirs.append(ocr)\n",
    "\n",
    "for row in test_sample:\n",
    "      adress = row[0]\n",
    "      lab = int(row[1])\n",
    "      seg = int(row[2])\n",
    "      ocr = row[3]\n",
    "      #label = np.array(label).astype(int)\n",
    "      addrs.append(adress)\n",
    "      labels.append(lab)\n",
    "      segmentation.append(seg)\n",
    "      ocr_dirs.append(ocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3551"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(addrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f6f4f78b6a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pytorch/vision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'densenet121'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'hub'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision', 'densenet121', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "feature_extracting = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "use_pretrained = True\n",
    "model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "set_parameter_requires_grad(model_ft, feature_extracting)\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier = nn.Linear(num_ftrs, 10)\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1508cabf4664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytePairEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# init embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Path'"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "import Path\n",
    "from flair.embeddings import BytePairEmbeddings\n",
    "\n",
    "# init embedding\n",
    "embedding = BytePairEmbeddings('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/en-wiki-fasttext-300d-1M'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_path_v4 = (\n",
    "    \"https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/\")\n",
    "embeddings = 'en'\n",
    "\n",
    "f\"{embeddings_path_v4}{embeddings}-wiki-fasttext-300d-1M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-24 18:01:57,071 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.3/en-fasttext-news-300d-1M not found in cache, downloading to /tmp/tmphl0dtnyl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54600983/54600983 [00:01<00:00, 37454263.67B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-24 18:01:58,816 copying /tmp/tmphl0dtnyl to cache at /home/bscuser/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-07-24 18:01:58,877 removing temp file /tmp/tmphl0dtnyl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "fast_text = WordEmbeddings('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Sentence: \". request personally , put I hope you understand the sensitivity that ”\" - 13 Tokens]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.embeddings import BytePairEmbeddings, Sentence\n",
    "\n",
    "# init embedding\n",
    "embedding = BytePairEmbeddings('en')\n",
    "print(embedding.embedding_length)\n",
    "\n",
    "# create a sentence\n",
    "sentence = Sentence('. request personally, put I hope you understand the sensitivity that”',use_tokenizer = True)\n",
    "\n",
    "# embed words in sentence\n",
    "embedding.embed(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5856,  0.5523, -0.3354, -0.1171, -0.3433, -0.0332,  0.0166,  1.1833,\n",
      "         0.0681,  0.5751,  0.0159,  0.1526, -1.1126,  0.1577,  0.1971, -0.2337,\n",
      "        -0.0967,  0.0749,  0.4202, -0.0612, -0.1640,  0.4570, -0.5658,  0.0820,\n",
      "         0.3273, -0.2498, -1.2409,  0.2872,  0.2371,  0.3297, -0.0793,  0.0299,\n",
      "        -0.4133, -0.0753, -0.1989, -0.3986, -0.2207,  0.0996,  0.1657, -0.0599,\n",
      "        -0.0053, -0.3639,  0.1914,  0.0638, -1.5809, -0.2949, -0.0881, -0.3183,\n",
      "        -0.0033,  0.0371, -0.5856,  0.5523, -0.3354, -0.1171, -0.3433, -0.0332,\n",
      "         0.0166,  1.1833,  0.0681,  0.5751,  0.0159,  0.1526, -1.1126,  0.1577,\n",
      "         0.1971, -0.2337, -0.0967,  0.0749,  0.4202, -0.0612, -0.1640,  0.4570,\n",
      "        -0.5658,  0.0820,  0.3273, -0.2498, -1.2409,  0.2872,  0.2371,  0.3297,\n",
      "        -0.0793,  0.0299, -0.4133, -0.0753, -0.1989, -0.3986, -0.2207,  0.0996,\n",
      "         0.1657, -0.0599, -0.0053, -0.3639,  0.1914,  0.0638, -1.5809, -0.2949,\n",
      "        -0.0881, -0.3183, -0.0033,  0.0371])\n",
      "tensor([-0.2268,  0.0767,  0.3012,  0.0471,  0.0820,  0.4824,  0.0548, -0.1221,\n",
      "        -0.0479, -0.1595,  0.4223, -0.6581,  0.0142,  0.3280, -0.0581,  0.1592,\n",
      "        -0.1190,  0.2164, -0.2023, -0.2133, -0.4022, -0.6541, -0.1643,  0.2395,\n",
      "         0.1868,  0.2340,  1.1133, -1.2552,  0.1680,  0.7973, -0.0576,  0.3695,\n",
      "        -0.9779,  0.4207, -1.1117, -0.1493, -0.2746, -0.1624, -0.1808, -0.6922,\n",
      "         0.2605,  0.5436,  0.6876, -0.4195,  0.4365,  0.4174, -0.6244, -0.5218,\n",
      "         0.3360, -0.5976, -0.2268,  0.0767,  0.3012,  0.0471,  0.0820,  0.4824,\n",
      "         0.0548, -0.1221, -0.0479, -0.1595,  0.4223, -0.6581,  0.0142,  0.3280,\n",
      "        -0.0581,  0.1592, -0.1190,  0.2164, -0.2023, -0.2133, -0.4022, -0.6541,\n",
      "        -0.1643,  0.2395,  0.1868,  0.2340,  1.1133, -1.2552,  0.1680,  0.7973,\n",
      "        -0.0576,  0.3695, -0.9779,  0.4207, -1.1117, -0.1493, -0.2746, -0.1624,\n",
      "        -0.1808, -0.6922,  0.2605,  0.5436,  0.6876, -0.4195,  0.4365,  0.4174,\n",
      "        -0.6244, -0.5218,  0.3360, -0.5976])\n",
      "tensor([-0.1866,  0.5280, -1.0116,  0.4169, -0.1664, -0.9098,  0.6915,  0.6655,\n",
      "        -0.5491,  0.2236,  0.3772,  0.3319, -0.2402,  0.1800, -0.4039,  0.1565,\n",
      "        -0.3056, -0.0114, -0.1140,  0.5272, -0.1889,  0.1585,  0.0958,  0.9225,\n",
      "        -0.1572, -0.1255, -1.3189,  0.1635,  0.6972,  0.5661, -0.4012,  0.6330,\n",
      "        -0.0752, -0.1147,  0.1681, -0.3840, -0.3728,  0.4368, -0.1956, -0.1691,\n",
      "         0.0704, -0.6942,  0.0227,  0.0618, -1.2336, -0.3819, -0.0040, -0.4201,\n",
      "         0.2203,  0.0800, -0.1866,  0.5280, -1.0116,  0.4169, -0.1664, -0.9098,\n",
      "         0.6915,  0.6655, -0.5491,  0.2236,  0.3772,  0.3319, -0.2402,  0.1800,\n",
      "        -0.4039,  0.1565, -0.3056, -0.0114, -0.1140,  0.5272, -0.1889,  0.1585,\n",
      "         0.0958,  0.9225, -0.1572, -0.1255, -1.3189,  0.1635,  0.6972,  0.5661,\n",
      "        -0.4012,  0.6330, -0.0752, -0.1147,  0.1681, -0.3840, -0.3728,  0.4368,\n",
      "        -0.1956, -0.1691,  0.0704, -0.6942,  0.0227,  0.0618, -1.2336, -0.3819,\n",
      "        -0.0040, -0.4201,  0.2203,  0.0800])\n",
      "tensor([-0.0755, -0.8742,  0.2042,  1.0616, -0.2461,  0.3552,  0.2628,  0.3877,\n",
      "        -0.5337,  0.2375, -0.5753, -0.2933, -1.3854,  0.4845, -0.3947,  0.4662,\n",
      "        -0.3503,  0.3839, -0.4909,  0.5113,  0.2292, -0.6994, -0.6007,  0.3549,\n",
      "         0.2109,  0.3148, -0.9653,  0.1728, -0.4916, -0.4178, -0.7608,  0.7871,\n",
      "        -0.3039,  0.5810,  0.0154,  0.1105, -0.5488, -0.2559, -0.7226, -0.7317,\n",
      "         0.7235, -0.6333,  0.6838,  0.7554, -1.2394, -0.1344,  0.6778, -0.4609,\n",
      "         0.2638, -0.0036, -0.0755, -0.8742,  0.2042,  1.0616, -0.2461,  0.3552,\n",
      "         0.2628,  0.3877, -0.5337,  0.2375, -0.5753, -0.2933, -1.3854,  0.4845,\n",
      "        -0.3947,  0.4662, -0.3503,  0.3839, -0.4909,  0.5113,  0.2292, -0.6994,\n",
      "        -0.6007,  0.3549,  0.2109,  0.3148, -0.9653,  0.1728, -0.4916, -0.4178,\n",
      "        -0.7608,  0.7871, -0.3039,  0.5810,  0.0154,  0.1105, -0.5488, -0.2559,\n",
      "        -0.7226, -0.7317,  0.7235, -0.6333,  0.6838,  0.7554, -1.2394, -0.1344,\n",
      "         0.6778, -0.4609,  0.2638, -0.0036])\n",
      "tensor([-0.2147,  0.2122, -0.6071,  0.5129, -0.3256,  0.2208, -0.3712,  1.1548,\n",
      "        -0.0595,  0.3382,  0.1074, -0.3109, -0.7043, -0.5039, -0.3101,  0.1500,\n",
      "         0.0888,  0.6306, -0.6351,  0.0741, -0.3744, -0.1120, -0.1191,  0.1893,\n",
      "         0.3136,  0.0117, -0.6044,  0.3977,  0.7467, -0.5820, -0.0789,  0.1626,\n",
      "         0.3100, -0.0591,  0.8583, -0.1298, -0.2150,  0.3992, -0.8243,  0.7244,\n",
      "        -0.4512, -0.3404, -0.3065,  0.0288, -0.8848,  0.5191,  0.2391,  0.6826,\n",
      "         0.2182,  0.4763, -0.2147,  0.2122, -0.6071,  0.5129, -0.3256,  0.2208,\n",
      "        -0.3712,  1.1548, -0.0595,  0.3382,  0.1074, -0.3109, -0.7043, -0.5039,\n",
      "        -0.3101,  0.1500,  0.0888,  0.6306, -0.6351,  0.0741, -0.3744, -0.1120,\n",
      "        -0.1191,  0.1893,  0.3136,  0.0117, -0.6044,  0.3977,  0.7467, -0.5820,\n",
      "        -0.0789,  0.1626,  0.3100, -0.0591,  0.8583, -0.1298, -0.2150,  0.3992,\n",
      "        -0.8243,  0.7244, -0.4512, -0.3404, -0.3065,  0.0288, -0.8848,  0.5191,\n",
      "         0.2391,  0.6826,  0.2182,  0.4763])\n"
     ]
    }
   ],
   "source": [
    "for token in sentence:\n",
    "        #print(token)\n",
    "        token_embedding = token.embedding\n",
    "        print(token_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
