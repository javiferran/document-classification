<!DOCTYPE html>
<html dir="ltr" lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Improving accuracy and speeding up Document Image Classication through parallel systems</title>
	<meta name="keywords" content="SinglePaged, jekyll, template, github, blog, single page">
	<meta name="description" content="Site for improving accuracy paper">
  <link rel="stylesheet" href="combo.css">
  <link href='http://fonts.googleapis.com/css?family=Raleway:400,300,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css">
  <link rel="shortcut icon" href="img/BSC-Logo.ico" type="image/x-icon">
	<link rel="apple-touch-icon" href="img/BSC-Logo.jpg">
</head>
<body>
  <div id="main">

    <nav><ul>
      
        
        <li class="p-intro"><a href="#intro">home</a></li>
      
        
        <li class="p-model"><a href="#model">Model</a></li>
      
        
        <li class="p-results"><a href="#results">results</a></li>
      
        
        <li class="p-usage"><a href="#usage">usage</a></li>
      
        
        <li class="p-datasets"><a href="#datasets">datasets</a></li>
      
        
        <li class="p-citation"><a href="#citation">citation</a></li>
      
    </ul></nav>


    
      
      <div id="intro" class="section p-intro">
        
        <div class="container center">
          <h1 class="text-white">Improving accuracy and speeding up Document Image Classication through parallel systems</h1>

<p>This paper presents a study showing the benefits of the EfficientNet models compared with heavier Convolutional Neural Networks (CNNs) in the Document Classification task.</p>

<p>We show in the RVL-CDIP dataset that we can improve previous results with a much lighter model and present its transfer learning capabilities on a smaller in-domain dataset such as Tobacco3482.
Moreover, we present an ensemble pipeline which is able to boost solely image input by combining image model predictions with the ones generated by BERT model on extracted text by OCR.</p>

<p>We also show that the batch size can be effectively increased without hindering its accuracy so that the training process can be sped up by parallelizing throughout multiple GPUs, decreasing the computational time needed. Lastly, we expose the training performance differences between PyTorch and Tensorflow Deep Learning frameworks.</p>

<p>Paper: <a href="">Improving accuracy and speeding up Document Image Classification through parallel systems</a></p>

<p><a href="https://github.com/javiferran/document-classification" class="btn btn-primary" role="button">View code on GitHub
  </a></p>

<!--
<span id="forkongithub">
  <a href="https://github.com/javiferran/document-classification" class="bg-blue">
    Fork me on GitHub
  </a>
</span>
-->

        </div>
      </div>
    
      
      <div id="model" class="section p-model">
        
        <div class="subtlecircle sectiondivider imaged">
          <img src="img/model_web.png" alt="section icon" />
          <h5 class="icon-title">Model</h5>
        </div>
        
        <div class="container center">
          <p>Parallel pre-training in BigTobacco and fine-tuning in SmallTobacco:</p>

<p><img src="./images/parallel_approach_v3-1_transparent.png" alt="ensemble" class="inline" width="600" /></p>

<p>SmallTobacco training/fine-tuning:</p>

<p><img src="./images/approach_horizontal_v3-1_transparent.png" alt="ensemble" class="inline" width="600" /></p>


        </div>
      </div>
    
      
      <div id="results" class="section p-results">
        
        <div class="subtlecircle sectiondivider imaged">
          <img src="img/results_web.png" alt="section icon" />
          <h5 class="icon-title">results</h5>
        </div>
        
        <div class="container center">
          <h3>Results comparison</h3>

<p><img src="./images/table2_transparent.png" alt="tfvspy" class="inline" width="600" /></p>

<h3>TensorFlow vs PyTorch distributed training</h3>

<p><img src="./images/tfvspy-1_transparent.png" alt="tfvspy" class="inline" width="600" /></p>


        </div>
      </div>
    
      
      <div id="usage" class="section p-usage">
        
        <div class="subtlecircle sectiondivider imaged">
          <img src="img/usage.png" alt="section icon" />
          <h5 class="icon-title">usage</h5>
        </div>
        
        <div class="container ">
          <h1>Image Model Distributed Training</h1>

<h2>PyTorch</h2>

<p><em>efficientnet_pytorch</em> library downloads the models in .cache/torch/checkpoints. In case your machine has no internet connection, make sure to add the models manually.</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5</pre></td><td class="code"><pre>python -m torch.distributed.launch eff_big_training_distributed.py \
	-n 1 -g 4 -nr 0 \
	--epochs 20 \
	--eff_model b0 \
	--load_path /gpfs/scratch/bsc31/bsc31275/<span class="w">
</span></pre></td></tr></tbody></table></code></pre></figure>

<ul>
  <li>
    <p><code class="highlighter-rouge">n</code>: number of nodes</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">g</code>: number of gpus in each node</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">nr</code>: the rank of the current node within all the nodes</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">epochs</code>: training number of epochs</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">eff_model</code>: EfficientNet model</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">load_path</code>: path where datasets are stored</p>
  </li>
</ul>

<h2>TensorFlow</h2>

<p><em>efficientnet.tfkeras</em> library downloads the models in .keras/models.</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>python distr_effnet_shear.py --image_model 0 --optimizer sgd --epochs 20<span class="w">
</span></pre></td></tr></tbody></table></code></pre></figure>

<ul>
  <li>
    <p><code class="highlighter-rouge">image_model</code>: : EfficientNet model</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">optimizer</code>: optimizer to be used</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">epochs</code>: training number of epochs</p>
  </li>
</ul>

<h1>Text Model (PyTorch)</h1>

<p>pytorch_transformers library downloads the models in .cache/torch/pytorch_transformers. BERT training is simply done by running <code class="highlighter-rouge">python main.py</code>. To get the ensemble results run <code class="highlighter-rouge">python ensemble.py</code>.</p>

<h3 style="margin-top:80px;">Also see <strong>README.md</strong> <a href="https://github.com/javiferran/document-classification/blob/master/README.md"><em>on github!</em></a></h3>


        </div>
      </div>
    
      
      <div id="datasets" class="section p-datasets">
        
        <div class="subtlecircle sectiondivider imaged">
          <img src="img/datasets.png" alt="section icon" />
          <h5 class="icon-title">datasets</h5>
        </div>
        
        <div class="container ">
          <h2>Datasets</h2>

<p>We provide the scripts to generate the .hdf5 and .TfRecord used <a href="https://github.com/javiferran/document-classification/tree/master/Data">here</a>.</p>

<p>Run <code class="highlighter-rouge">python ./Data/python BT_hdf5_dataset_creation.py</code> to create the .hdf5 files for train, test and validation sets.</p>

<p>For SmallTobacco, we provide the scripts for both optaining Tesserect OCR .txt files and generating random splits .hdf5 files.</p>

<p>Run:</p>

<ul>
  <li>
    <p><code class="highlighter-rouge">python ./Data/ocr_tobacco.py</code> to extract OCR and save .txt files in the same path as the images.</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">python ./Data/python ST_hdf5_dataset_creation.py</code> to create the .hdf5 file dataset.</p>
  </li>
</ul>

<p>Please contact the repository owner for more information.</p>

        </div>
      </div>
    
      
      <div id="citation" class="section p-citation">
        
        <div class="subtlecircle sectiondivider faicon">
          <span class="fa-stack">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-comments fa-stack-1x"></i>
          </span>
          <h5 class="icon-title">citation</h5>
        </div>
        
        <div class="container ">
          <p>If you find this paper useful, consider citing:</p>

<pre>
@inproceedings{improvingiccs2020,
  title={Improving accuracy and speeding up Document Image Classication through parallel systems},
  author={Javier Ferrando, Juan Luis Domínguez, Jordi Torres, Raúl García, David García,
	 Daniel Garrido, Jordi Cortada, Mateo Valero},
  booktitle={2020 International Conference on Computational Science (ICCS)},
  year={2020},
}
</pre>

        </div>
      </div>
    


    <div id="footer" class="section text-white">
      <div class="container">
        
        
<p>Design by Tim O’Brien <a href="http://t413.com/">t413.com</a>
—
<a href="https://github.com/t413/SinglePaged">SinglePaged theme</a>
—
this site is <a href="https://github.com/javiferran/document-classification">open source</a></p>


      </div>
    </div>
  </div>


<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-49607422-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

</body>
<script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
<script src="site.js"></script>
</html>
