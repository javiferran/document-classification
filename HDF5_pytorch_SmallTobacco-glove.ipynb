{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import numpy\n",
    "import h5py\n",
    "\n",
    "from PIL import Image, ImageSequence\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torchtext.data as data\n",
    "import torchtext.datasets as datasets\n",
    "\n",
    "import os\n",
    "import tensorwatch as tw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz\n",
    "import numpy as np\n",
    "import pickle\n",
    "from segtok.tokenizer import split_contractions\n",
    "from segtok.tokenizer import word_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "idx = 0\n",
    "word2idx = {}\n",
    "vectors = bcolz.carray(np.zeros(1), rootdir=f'./Data/6B.100.dat', mode='w')\n",
    "\n",
    "with open(f'./Data/glove.6B.100d.txt', 'rb') as f:\n",
    "    for l in f:\n",
    "        line = l.decode().split()\n",
    "        word = line[0]\n",
    "        words.append(word)\n",
    "        word2idx[word] = idx\n",
    "        idx += 1\n",
    "        vect = np.array(line[1:]).astype(np.float)\n",
    "        vectors.append(vect)\n",
    "    \n",
    "vectors = bcolz.carray(vectors[1:].reshape((400000, 100)), rootdir=f'./Data/6B.100.dat', mode='w')\n",
    "vectors.flush()\n",
    "pickle.dump(words, open(f'./Data/6B.100_words.pkl', 'wb'))\n",
    "pickle.dump(word2idx, open(f'./Data/6B.100_idx.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = bcolz.open(f'./Data/6B.100.dat')[:]\n",
    "words = pickle.load(open(f'./Data/6B.100_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open(f'./Data/6B.100_idx.pkl', 'rb'))\n",
    "\n",
    "glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'berlin']\n"
     ]
    }
   ],
   "source": [
    "test_ocr = 'I love berlin'\n",
    "tokenized_ocr = split_contractions(word_tokenizer(test_ocr))\n",
    "print(tokenized_ocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file='./HDF5_files/hdf5_10.hdf5'\n",
    "h5_file = h5py.File(hdf5_file, \"r\")\n",
    "ocr = h5_file.get('train_ocrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oe', 'the', 'sunday', 'star', 'washington', ',', 'd.c.', 'june', 'y', '1963', 'heart', 'association', 'moves', 'to', 'reduce', 'cigarette', 'use', 'new', 'yore', ',', 'june', '8', '(', 'ap', ')', '—', 'the', 'american', 'heart', 'associa-ulon', 'went', 'on', 'record', 'today', 'foi', 'the', 'first', 'time', 'in', 'favor', 'of', 'acthe', 'steps', 'to', 'discourage', 'clparettr', 'smoking', 'on', 'the', 'ground', 'it', 'fr', 'heimtul', 'to', 'health', ',', 'the', 'action', 'by', 'the', 'board', 'of', 'directors', 'opens', 'the', 'way', 'fc', 'the', 'asvocjution', 'to', 'work', 'with', '«', 'ther', 'proips', 'in', 'campaizns', 'fiist', 'poking.', 'the', 'association', 'said', 'a', 'i56', '¢', 'wport', 'by', '4', 'spectal', 'committer', 'of', 'physicians', 'and', 'scientists', 'shawed', 'that', 'dcath', 'rates', 'ir', 'middle-aged', 'men', 'from', 'heart', 'attacks', 'were', '60', 'to', '150', 'per', 'cen', ':', 'hicher', 'among', 'heavy', 'ciynrett', ':', 'snvakers', 'than', 'among', 'nou-emckers', ',', '“', 'this', 'statistical', 'assnoialiot', '¢', 'es', 'not', 'prove', 'that', 'heary', 'cit', 'aceite', 'emoking', 'causes', 'cord’', '.', '.', 'heart', 'disease.', '”', 'it', 'sald.', '“', 'but', 'th', 'data', 'strongly', 'suggests', 'ta', 'heavy', 'cigarette', 'smoking', 'ma-contribute', 'to', 'or', 'accelerate', 'th', 'development', 'of', 'coronary', 'hens', 'disrase', 'or', 'ils', 'complications', '”', 't.', 'saad', 'additional', 'evicdcenec', 'shee', '1960', 'conffrms', 'ard', 'hie', 'cement', 'oh', 'oogeloy', 'geck', 'the', 'plain', 'dealer', 'cleveland', ',', 'ohio', 'june', '9', ',', '1963', 'aera', 'smoking', 'discouraged', 'by', 'heart', 'association', 'new', 'york', '(®--', 'the', 'american', 'heart', 'association', 'went', 'on', 'record', 'yesterday', 'for', 'the', 'first', 'time', 'in', 'favor', 'of', 'active', 'steps', 'to', 'courage', 'cigarette', 'smoking', 'on', 'the', 'ground', 'it', 'is', 'harmful', 'to', 'health.', '8', 'are', 'the', 'action', 'by', 'the', 'board', 'of', 'directors', 'opens', 'the', 'way', 'for', 'the', 'association', 'tn', 'work', 'with', 'other', 'groups', 'in', 'campaigns', 'against', 'smoking.', '_', 'the', 'association', 'said', 'a', '1960', 'report', 'by', 'a', 'special', 'cunmmittee', 'of', 'physicians', 'and', 'scientists', 'showed', 'that', 'death', 'rates', 'in', 'mid', ':', 'die-aged', 'men', 'from', 'heart', 'attacks', 'were', '50', 'to', '150', \"'-\", 'tugher', 'among', 'heavy', 'cigarelte', 'smokers', 'than', 'among', 'non-smokers.', 'it', 'said', 'additional', 'evidence', 'since', '1960', 'confirms', 'and', 'supplements', 'the', 'earlier', 'find.', 'ngs', '1', 'et', 'nnn', 'eee', 'three', '|', 'chicago', 'tribune', 'chicago', ',', 'illinois', 'june', '9', ',', '1953', 'heart', 'society', 'finds', 'cigarets', 'abet', 'attacks', 'new', 'york', ',', 'june', '8', '(#--', 'the', 'american', 'heart', 'association', 'went', 'on', 'record', 'today', 'for', 'the', 'first', 'time', 'in', 'favor', 'of', 'active', 'steps', 'to', 'discourage', 'cigaret', 'smoking', 'on', 'the', 'ground', 'it', 'is', 'harmful', 'to', 'health.', 'the', 'acti', 'by', 'the', 'board', 'of', 'directors', 'opens', 'the', 'way', 'for', 'the', 'association', 'to', 'work', 'with', 'other', 'groups', 'in', 'campaigns', 'against', 'smoking.', 'the', 'association', 'said', 'a', '2060', 'report', 'by', 'a', 'special', 'of', 'physicians', 'and', 'sclentists', 'showed', 'that', 'death', 'rates', 'in', 'middle-aged', 'men', 'from', 'heart', 'attacks', 'were', '60', 'to', '150', 'per', 'cent', 'higher', 'among', 'heavy', 'cigarel', 'emeckers', 'than', 'among', 'fon-smeckers.', '“', 'these', 'slatistics', 'do', 'not', 'prove', 'that', 'heavy', 'cigaret', 'smoking', 'causes', 'corcnary', 'heart', 'disease', ',', 'it', 'sald', ',', '“', 'but', 'the', 'data', 'strongly', 'suggests', 'that', 'heavy', 'cigarel', 'smoking', 'may', 'contribute', 'to', 'or', 'accelerate', 'the', 'development', 'of', 'coronary', 'heart', 'disease', 'or', 'its', 'complications.', '”', '1180034005', 'lungcancer', 'called', 'big', 'killer', 'of', '2-pack-a-day', 'smokers', 'by', 'pierre', 'c.', 'fraley', 'survey.', 'careinoma', 'of', 'the', 'lunr', 'of', 'the', 'bulletin', 'stajs', 'laccounted', 'for', '12', 'per', 'cent', 'of', 'all', 'auantic', 'city', ',', 'june', '6', '--', 'the', '|', '928ths', 'in', 'this', 'group', 'and', 'was', 'sec', '-', 'american', 'cancer', 'socicty', \"'s\", 'long', '-', 'ond', 'only', 'beroneny', 'artery', 'dis', 'range', 'study', 'of', '188.000', 'men', 'be', '-', '|', '“\"', 'srne', 'death', 'rate', 'from', 'carcinoma', 'tween', 'the', 'ages', 'of', '50', 'and', '70', 'con.', 'of', 'the', 'lung', 'increases', 'with', 'the', 'tinues', 'to', 'indicate', 'that', 'lung', 'can', '-', 'lamount', 'of', 'cigarette', 'smoking.', 'cer', 'and', 'cigarette', 'smoking', 'go', 'hand-in-hand.', 'less', 'with', 'pipe', 'smokers', 'dr.', 'e.', 'cuyler', 'hammond', ',', 'diree-j', 'lung', 'cancer', 'also', 'appears', 'to', 'be', 'tor', ',', 'and', 'dr.', 'daniel', 'horn', ',', 'assist', ':', '{', 'associated', 'with', 'pipe', 'smoking', 'but', 'ant', 'director', 'of', 'statistical', 're', '‘', 'to', 'a', 'far', 'lesser', 'degree', 'than', 'with', 'search', ',', 'reported', 'today', 'at', 'the', '{', 'cigarette', 'smoking.', 'there', 'seems', '104th', 'annual', 'meeting', 'of', 'the', '!', 'to', 'be', 'no', 'significant', 'tieup', 'between', 'american', 'medical', 'association', 'on', '{', 'cigar', 'smoking', 'and', 'lung', 'cancer.', 'a', '2-month', 'follow-up', 'on', 'the', 'the', 'rate', 'of', 'lung', 'cancer', 'was', 'smoking', '‘', 'habits', 'and', 'fate', 'of', 'menyhigh', 'in', 'cigarette', 'smokers', 'and', 'low', 'in', 'this', 'age', 'group.', 'in', 'non-smokers', 'regardless', 'of', 'the', 'report', 'is', 'an', 'extension', 'of', '|', 'whether', 'they', 'lived', 'in', 'a', 'city', 'or', 'in', 'the', 'ene', 'at', 'the', 'ama', 'convention', '!', 'the', 'country.', 'however', ',', 'smoking', 'last', 'year', 'dealing', 'with', 'overalljhabits', 'were', 'not', 'able', 'to', 'account', 'death', 'rates', 'that', ',', 'caused', 'tobacco', '}', 'for', 'all', 'of', 'the', 'higher', 'death', 'rate', 'stocks', 'to', 'plummet', 'a', 'total', 'of', '$', '77', ',-|', 'from', 'lung', 'cancer', 'in', 'urban', 'areas', '000,000', 'in', 'a', 'few', 'days.', 'oo', 'with', 'rural', 'areas.', 'during', 'the', 'months', 'of', 'the', 'bare', 'among', 'non-smokers', '|', 'survey', 'there', 'were', '152', 'deaths', 'today', \"'s\", 'report.', 'concentrating', 'from', 'earcinoma', 'of', 'the', 'lung', 'mainly', 'on', 'the', 'most', 'widespread', 'among', 'the', '108000', 'men', 'who', 'said', 'type', 'of', 'lung', 'cancer', ',', 'carcinoma', ',', 'cam', ':', 'to', 'these', 'conclusions', ':', 'ratio', 'of', '145', 'out', 'of', 'every', '100,000.', 'compares', 'with', 'a', 'death', 'rate', 'men', 'who', 'have', 'never', 'smoked.', '”', 'it', 'is', '“', 'an', 'important', 'cause', 'of', 'death', 'among', 'men', 'i', '“', 'in', 'this', 'group', 'the', 'rate', 'for', 'men', 'smoking', 'twoor', 'more', ',', '.', 'packs', 'of', 'cigarettes', 'a', 'day.', '\"', 'iwith', 'history', 'of', 'regular', 'cigar-there', 'were', '4430', 'men', 'who', 'cle', 'smoking', 'was', 'about', '29', 'times', 'smoked', 'two', 'packs', 'or', 'more', 'in', 'the', '%', '8', 'high', 'as', 'the', 'rate', 'for', 'men', 'who', 'never', 'smoked', ',”', 'the', 'doctors', 're', '-', 'ported.', 'the', 'evening', 'bulletin', 'industryraps', '|\"', 'sue', '\"', '6,isss', 'cancer', 'report', '|', 'ov.', '\"', 'scoerar', 'ars', 'attacks', 'figures', 'new', 'york', ',', 'june', '6', '—(', 'up', ')—', 'timothy', 'b.', 'hartnett', ',', 'chairman', 'of', 'the', 'tobacco', 'industry', 'research', 'comittee', ',', 'today', 'urged', 'smokers', 'mot', 'to', 'be', '“', 'misled', 'by', 'sweeping', 'generalities', '”', 'in', 'a', 'doctors’', 'report', 'on', 'the', 'relationship', 'between', 'jat', 'the', 'start', 'of', 'the', 'survay', 'over', 'three', 'years', 'ago', ',”', 'he', 'sald.', 'hartnett', 'also', 'charged', 'that', 'the', 'quertionnaire', 'used', 'by', 'drs.', 'e', 'cuyler', 'hammond', 'and', 'daniel', 'horn', 'contained', 'bias', '“', 'so', 'great', 'as', 'to', 'make', 'questionable', 'the', 'validity', '{', 'ef', 'any', 'conclusions', '...”', 'same', 'of', 'amoking', 'and', 'lung', 'cancer.', '—', '§', 'uhe', 'questions', 'were', 'yeading', ',', 'hort-hartnett', ',', '@', 'hose', 'organization', ']', 'nett', 'said', ',', 'and', 'use', 'of', 'the', 'term', 'is', 'conducting', 'its', 'own', 'survey', 'into', '|', '‘', 'heavy', 'smoking', '”', 'suggested', 'excess', 'lung', 'cancer', ',', 'charged', 'that', 'the', 're', '-)', 'which', '“', 'doctors', 'generally', 'oppose', 'port', 'releared', 'today', 'in', 'atlantic', '}', '«..', 'in', 'any', 'human', 'ectivity.', 'city', '“', 'ignores', 'important', 'enviror', '-}|', 'laboratory', 'rescareh', 'during', 'the', 'mental', ',', 'georraphical', ',', 'occupation', '-/', 'past', 'year', 'has', 'failed', 'to', ',', 'provide', 'al', ',', 'physical', 'and', 'emotional', 'factors', '/', '@', 'ny', 'proof', 'that', 'smoking', 'causes', 'eflecting', 'disease', 'and', 'longevity.', '”', '|', 'lung', 'cancer.', 'hartnett', 'sald.', 'they', 'smoked', 'regularly.', 'this', 'is', 'ai', 'eg', '“', 'the', 'rate', 'for', 'two-pack-a-day-or-more', 'cigarette', 'smokers', 'is', 'over', '90', 'times', 'as', 'high', 'as', 'the', 'rate', 'for', 'men', 'who', 'have', 'never', 'smoked', ',”', 'the', 'report', 'went', 'on.', '“', 'the', 'rate', 'for', 'men', 'who', 'have', 'given', 'up', 'cigarette', 'smoking', 'is', '14', 'times', 'as', 'high', 'as', 'the', 'rate', 'for', 'men', 'who', 'have', 'never', 'smoked', 'but', 'only', 'half', 'as', 'high', 'as', 'for', 'men', 'who', 'were', 'smoking', 'less', 'than', 'a', 'pack', 'of', 'cigarettes', 'a', 'da', ')', 'at', 'the', 'time', 'of', 'que-tinnine.', '”', '|', 'in', 'the', 'light', 'of', 'these', 'findings.', '{', 'ir', 'doctors', 'said', ',', 'it', 'seems', 'prob-able', 'that', 'giving', 'up', 'smoking', 'even', 'after', 'years', 'of', 'regular', 'smoking', 'may', 'result', 'in', 'a', 'reduction', 'in', 'the', 'rivk', 'of', 'developing', 'sung', 'cancer.', 'however', ',', 'the', 'number', 'of', 'cases', ':', 'mow', 'available', 'for', 'detailer', '!', 'analy', '-*', 'sis', 'is', 'not', 'great', 'enough', 'to', 'state', 'that', 'such', 'a', 'conclusion', 'has', 'been', ';', 'proved', 'beyond', 'reasonable', 'doubt.', '\"', 'more', 'evidence', 'is', 'needed', ',', 'they’', 'sai', ':', 'survey', 'of', 'specialists', 'tn', 'another', 'type', 'of', 'survey', 'con', '-|', 't', 'ducied', 'by', 'the', 'american', 'cancer', 'society', ',', 'a', 'majority', 'of', 'chest', 'sur-geons', ',', 'cancer', 'researchers', 'and', 'pathologists', 'who', 'were', 'questiou-ed', 'said', 'they', 'believed', 'heavy', 'agar-ette', 'smoking', 'may', 'lead', 'to', 'lung', 'cancer.', 'dr.', 'charles', 's.', 'cameron', ',', 'medi-1', 'and', 'scientific', 'director', 'of', 'the', 'acs', ',', 'reported', 'on', 'the', 'results', 'of', 'a', 'prg', 'sued', '?', 'the', 'evening', 'bulletin', 'fniladelphia', ',', 'penna.', 'june', '6', ',', '1955', 'sixty-three', 'per', 'cent', 'of', 'the', 'chest', 'surgeons.', '54', 'per', 'cent', 'of', 'the', 'researchers', 'and', 'half', 'of', 'the', 'path-ologists', 'checkei', '“', 'yes', '”', 'to', 'the', 'statement', 'that', 'heavy', 'smoking', 'of', 'cigarettes', 'may', 'lead', 'to', 'lung', 'can-cer', ',', 'the', '“', 'no', \"'s\", '”', 'ranged', 'from', 'four', 'to', 'seven', 'per', 'cent.', 'the', 'remainder', 'were', 'uncertain.', 'the', '\\\\-', 'o', 'reports', 'were', 'presented', 'at', 'a', 'symposium', 'on', '@', 'ancer', 'and', 'medicine', 'at', 'the', 'opening', 'session', '{', 'of', 'the', 'ama', 'convention.', '25,000', 'are', 'attending', 'some', '13.000', 'doctors', 'and', '12,000', 'guests', 'are', 'scheduled', 'to', 'attend', 'the', 'week-long', 'series', 'of', 'meetings.', 'on', 'tuesday', 'evening.', 'dr.', 'elmer', '|', 'hess.', 'of', 'erie', ',', 'will', 'be', 'inaugurated', 'as', 'president', 'of', 'the', 'ama.', 'he', 'suce', 'ceeds', 'dr.', 'walter', 'b.', 'martin', ',', 'of', 'norfolk', ',', 'va.', 'another', 'highlight', 'of', 'the', 'con-vention', 'will', 'be', 'a', 'symposium', 'on', 'the', 'contro', '!', 'of', 'polio.', 'among', 'the', 'experts', 'scheduled', 'to', 'participate', 'are', 'dr.', 'jonas', 'e.', 'salk', ',', 'developer', 'of', 'the', 'polio', 'vaccine', ';', 'dr.', 'leonard', 'a.', 'scheele', ',', 'surgeon', 'general', 'of', 'the', 'u.', 's.', 'public', 'health', 'service.', 'and', 'dr.', 'thomas', 'francis', ',', 'jr', ',', 'of', 'the', 'university', 'of', 'michigan.', 'who', 're-ported', 'on', 'the', 'success', 'of', 'the', 'vac', 'cine', 'used', 'in', 'a', 'mass', 'test', 'last', 'year.', 'detroit', 'free', 'press', 'detroit', ',', 'michigan', 'june', '7', ',', '1955', 'doctors', 'file', 'report', 'cancer', 'danger', 'seen', 'in', 'use', 'of', 'whisky', 'gpoelal', 'to', 'the', 'free', 'press', 'atlantic', 'city', '—', 'whisky-drinking', 'has', 'been', 'added', 'to', 'smoking', 'as', 'a', 'possible', 'cause', 'of', 'cancer', ',', 'three', 'physicians', 'revealed', 'here', 'monday', 'in', 'a', 'report', 'to', 'the', 'american', 'medical', 'association.', 'the', 'risk', 'of', 'tons', 'greatiy', 'or', 'voice', 'larynx', ',', '2', 'cia', ',', 'by', 'haa', 'ema', 'with', 'heavy', 'drinking.', 'port', 'on', 'interviews', 'in', 'sweden', ',', 'india', 'an', '¢', 'the', 'united', 'states', ',', 'ben', 'more', 'than', 'siz', 'eamokers', ',', 'they', 'found', ',', 'ut', 'the', 'same', 'risk', 'as', 'men', 'who', 'amoke', '16', 'to', '34', 'cigarets', '——', 'ae', 'and', 'run', 'oking', 'alone', ',', 'or', 'com', '-/', 'dally', ',', 'from', 'this', 'and', 'other', 'studies', ',', 'opinion', 'research', 'authorities', '”', 'con', '-', 'they', 'sald', 'the', 'risk', 'of', 'cancer', 'inj', 'sidered', 'that', 'the', 'poll', 'was', '“', 'biased', ',', 'tha', 'larynx', 'increases', 'with', 'tho', '/', 'nonscientific', 'q', '@', 'mount', 'of', 'elgarets', 'amoked.', 'cigariahortcomings', 'and', 'and', 'filled', 'with', 'defect', '”', '‘', 'of', 'utes', 'hoveber', '10', ',', '1982', '<', 're', ':', 'grant', 'no.', '1357r1', 'fabian', '3.', 'ionetti', ',', 'ph.d', ',', ',', 'boston', 'univeraity', 'school', 'of', 'medicine', 'no', '89', 'hast', 'concord', 'street', '(', 'le', 'boston', ',', 'ma', '02115', '~', 'dear', 'doctor', 'lionettd', ':', ':', 'the', 'council', ']', 'for', 'tabacco', 'research', '-', 'u.s.a.', ',', 'inc.', 'is', 'pleased', 'to', 'avard', 'you', '@', 'yenewal', 'grant', 'in', 'ths', 'awournt', 'of', '$', '48,990', 'fer', 'the', 'pericd', 'december', '1', ',', '1951', 'throwh', 'novernber', '30', ',', '1982', 'for', 'the', 'etudy', 'proposed', 'in', 'your', 'application', 'dated', '?', 'dune', '20', ',', '1981.', 'it', 't', 'is', 'mdorstood', 'that', 'this', 'grant', 'is', 'made', 'subject', 'to', 'scoeptance', 'by', 'the', 'institutional', 'authorities', ',', 'as', 'heretofore', 'since', 'it', 'concludes', 'the', 'period', 'originally', 'rrocranamd', 'for', 'this', 'bowity', ',', 'it', 'is', 'considerad', 'terminal', 'for', 'the', 'project', ',', 'and', 'a', 'comprehensive', 'final', 'report', 'will', 'be', 'esoncted', 'at', 'your', 'convenience', 'after', 'its', 'temaination', ',', 'as', 'wll', 'as', 'reprints', 'of', 'any', 'papers', 'resulting', 'from', 'the', 'oremt', 'thereafter.', 'rew', 'proposals', 'may', 'be', 'acceytable', 'for', 'consideration', 'de', 'novo', 'in', 'ommpetition', 'for', 'available', 'funds', 'in', 'the', 'licht', 'of', 'progras', 'status', 'and', 'priorities', 'et', 'the', 'tive', 'of', 'suizalnsion.', 'if', 'you', 'plan', 'te', 'submit', 'ary', 'euch', 'proposals', ',', 'it', 'will', 'be', 'well', 'to', 'send', 'in-formal', 'outlinas', 'of', 'the', 'arojects', 'you', 'have', 'in', 'mind', ',', 'as', 'carly', 'as', 'possible', ',', 'so', 'that', 'our', 'program', 'planning', 'grow', '?', 'can', 'advise', 'you', 'wheather', 'forvel', 'application', 'can', 'be', 'recommended.', 'these', 'msy', 'be', 'handled', 'through', 'your', 'cik', 'staff', 'contact.', 'your', 'attantion', 'is', 'particularly', 'called', 'to', 'the', 'enclose', '?', '“', 'important', 'prooaiural', 'informtion', 'for', 'grantees', '\".', 'dr', ',', 'vincent', 'f.', 'limanti', ',', 'associate', 'research', 'director', ',', 'will', 'continue', 'to', 're-present', 'our', 'sclentific', 'staff', 'as', 'primary', 'contact', 'with', 'your', 'crant.', 'ie', 'will', 'le', 'the', 'per', 'son', 'to', 'consult.', 'about', 'any', 'questions', 'or', 'problems', 'that', 'may', 'erise', ',', 'and', 'should', 'be', 'kept', 'informed', 'about', 'the', 'srocress', 'of', 'the', 'stirty.', 'please', '£', '311', 'in', 'the', 'atbached', '“', 'notice', 'of', 'rasearch', 'projost', '™', 'anc', 'return', 'it', 'to', 'me.', 'cordially', ',', '12,047.50', '&', 'robert', 'f.', 'gertenbach', 'encis.', 'co', ':', 'robert', 'n.', 'jorian', 'reg', ':', 'am', 'bee', ':', 'audftor', ',', 'f', ',', \"ro'k\", ',', 'vel', ',', 'bc', 'sen.', 'bs', 'everett', 'jordan', ':', 'repe', 'le', 'h.', 'fountain', ':', 'rep.', 'harley', 'staggers', ':', 'rep.', 'edward', 'i.koch', ':', 'hkeo485294', '“', 'regarded', 'the', 'fcc', 'ban', 'as', '‘', 'an', 'unwarranted', ',', '111-advised', 'and', 'improper', 'effort', 'to', 'extend', 'governnent', 'control', 'over', 'business', 'and', 'industry', 'by', 'administrative', 'dictation.', '\"\"]', 'regard', 'the', 'proposal', 'of', 'the', 'federal', 'communications', 'commission', 'for', 'a', 'ban', 'on', 'advertising', 'of', 'cigarettes', 'through', 'television', 'and', 'radio', 'media', 'as', 'an', 'unwarranted', ',', '111l', '~', 'advised', 'and', 'improper', 'effort', 'to', 'extent', 'government', 'control', 'over', 'business', 'and', 'industry', 'by', 'administrative', 'dictation.', '\"', 'tle', '4s', 'an', 'extention', 'of', 'earlier', 'efforts', ',', 'successfully', 'resisted', 'so', 'far', 'by', 'congress', ',', 'by', 'both', 'the', 'federal', 'trade', 'commission', 'and', 'the', 'fcc', 'to', 'exereise', 'control', 'over', 'the', 'tobacco', 'industry', 'beyond', 'the', 'extent', 'of', 'their', 'authority', 'and', 'in', 'an', 'area', 'properly', 'reserved', 'for', 'legislative', 'jurisdiction', ',', '’', '(', 'upi', '2', '/', '5', '/', '69', ')', '\"', 'said', 'he', 'knew', 'of', 'no', 'legal', 'authority', 'by', 'which', 'fcc', 'could', 'enforce', 'its', 'proposed', 'ban', 'on', 'broadcast', 'cigarette', 'advertising.', '\"', '(', 'upi', '2', '/', '5', '/', '69', ')', '\"', 'forecasting', 'early', 'hearings', 'on', 'the', 'issue', ',', 'offered', 'a', 'critical', 'comment', 'that', 'seemed', 'to', 'reflect', 'a', 'common', '‘', 'attitude', 'on', 'the', 'part', 'of', 'committee', 'nembers', ',.', '\"\\'', 't', 'think', 'some', 'of', 'the', 'regulatory', 'agencies', 'are', 'doing', 'sone', 'of', 'those', 'things', 'the', 'wrong', 'way.', '.', '\"\\'', 'rhey', \"'ve\", 'been', 'guilty', 'of', 'it', 'before', '=-', 'taking', 'a', 'stand', 'of', 'this', 'kind', 'on', 'an', 'issue', 'which', 'they', 'know', 'the', 'congress', 'would', 'probably', 'be', 'considering', 'shortly.', '1', 'do', \"n't\", 'think', 'congress', 'likes', 'this', 'approach', '--', 'and', 'that', 'is', 'without', 'regard', 'to', 'the', 'particular', 'issue', 'of', 'cigarette', 'smoking.', '\\'\"', '(', 'upi', '2', '/', '5', '/', '69', ')', '\"', 'a', 'federal', 'communications', 'proposal', 'to', 'ban', 'cigarette', 'advertising', 'from', 'television', 'and', 'radio', 'was', '‘', 'long', 'overdue.’', '\"', 'he', 'will', 'do', 'what', 'he', 'can', 'to', 'whip', 'up', 'congressional', 'support', 'for', 'the', 'fcc', 'proposal', ',', 'he', 'called', 'on', 'members', 'of', 'the', 'public', 'to', 'direct', 'their', 'support', 'to', 'the', 'fcc', '-', 'and', 'their', 'congresamen.', '\"\"', 'we', 'are.', 'going', 'to', 'have', 'a', 'fight', 'on', 'our', 'hands', ',\\'\"', '(', 'upt', '2', '/', '5', '/', '69', ')', '\\\\', 'cassette', 'recorders', 'up', '150', '%', 'sales', 'expected', 'to', 'hit', '$', '350', 'million', 'in', '1970', ';', 'tape', 'volume', 'also', 'soars', 'time', 'was', 'when', 'only', 'a', 'relatively', 'few', 'americans', 'owned', 'tape', 'tre-corders.', 'most', 'of', 'them', 'were', 'the', '“', 'hi-fi', 'hobbyists.', 'who', 'were', 'willing', 'to', 'put', 'up', 'with', 'the', 'need', 'for', 'threading', 'tape', 'from', 'one', 'reel', 'to', 'another', '...', 'with', 'the', 'agony', 'of', 'watching', 'tape', 'come', 'spilling', 'out', 'of', 'the', 'machinery', 'in', 'wild', 'disarray', 'because', 'of', 'some', 'malfunction.', 'the', 'dedicated', 'hi-fi', 'aficionados', 'stil', ']', ',', 'for', 'the', 'most', 'part', ',', 'stay', 'with', 'their', 'open-reel', 'machines.', 'but', 'mil-lions', 'of', 'the', 'more', 'fumble-fingered', 'public', 'have', 'come', 'into', 'the', 'tape', 're-corder', 'market', ',', 'as', 'a', 'result', 'of', 'the', 'ad-yent', 'of', 'the', 'cassette', '—', 'the', 'self-con-tained', 'unit', 'in', 'which', 'tape', 'moves', 'from', 'one', 'reel', 'to', 'the', 'other', 'without', 'need', 'for', 'the', 'user', 'ever', 'to', 'touch', 'the', 'reel', 'or', 'the', 'tape.', 'so', 'papular', ',', 'so', 'ubiquitous', 'has', 'the', 'cassette', 'recorder', 'become', 'that', 'indus-try', 'leaders', 'estimate', 'u.', 's.', 'retail', 'vol-ume', 'will', 'reach', '$', '350', 'million', 'in', '1970.', 'this', 'would', 'represent', 'an', 'increase', 'of', 'more', 'than', '150', '%', 'over', '1969.', 'american', 'druggist', \"'\", '’s', 'most', 're-cent', 'big', 'ticket', 'survey', 'indicated', 'that', 'more', 'than', '16,000', 'drug', 'stores', 'car-ried', 'cassette', 'recorders.', 'nor', 'is', 'the', 'business', 'limited', 'to', 'the', 'recording', 'devices.', 'a', 'cassette', 're-corder', 'is', 'of', 'no', 'use', 'without', 'cassette', 'tape', '—', 'and', 'sales', 'of', 'blank', 'tape', 'are', 'expected', 'to', 'exceed', '$', '80', 'million', 'this', 'year.', 'while', 'no', 'one', 'knows', 'for', 'sure', '—', 'because', 'the', 'market', 'is', 'still', 'in', 'its', 'for-mative', 'stages', '—', 'what', 'percentage', 'of', 'the', 'business', 'is', 'done', 'by', 'drug', 'stores', ',', 'guesses', 'by', 'those', 'in', 'the', 'field', 'vary', 'from', '151', '%', 'to', '17', '%.', 'buying', 'guide', '91', 'wer', 'product', 'grams', '“', 'ot', '-', 'ake', '7', 'ae', 'ae', 'ee', '.', 'ot', '—', '“', 'ot', 'ts', 'wm', 'tor', 'fe', 'sty', 'te', '‘$', 'ristol', 'labs', 'has', 'shanged', 'its', 'cash', 'dis', '-', '“', 'gount', 'policy', 'to', '2', '%-', '35', 'days', ',', 'net', '45', 'days', ',', 'based', 'on', 'date', 'of', 'invoisé', ',', 'retroactive', 'to', 'july', '1.', '°', '0n', 'july', '1', ',', 'the', 'company', 'had', 'adopted', '-', 'a', 'policy', 'of', '2', '%-', '15', 'days', ',', 'net', '30', 'days.', 'but', 'it', 'reports', 'that', '“', 'how', 'that', 'we', 'have', 'had', 'a', 'month', \"'s\", 'experience', 'behind', 'us', ',', 'we', 'realize', 'these', 'terms', 'placed', 'an', 'untimely', 'burden', 'on', 'our', 'customers.', '”', '-', 'a', 'philips', 'roxane', 'has', 'rescinded', 'a', 'change', 'in', '———', '_', 'wholesaler', 'terms', 'from', '1', '%-', '30', 'days', 'to', '1', '%-', '10', 'days.', '\"', 'wefind', '[', 'the', 'change', ']', 'willworkacons', 'ider-able', 'hardship', 'onmany', 'wholesalers', ',\"', 'the', 'company', 'said.', '\"', 'philips', 'roxane', 'remains', 'a', '20', '%', 'lire', 'at', '1', '%-', '30', 'days.', '\"', 'a', 'trademark', 'applications', 's', '\"', 'clockwork', '\"', ',', 'for', 'a', 'laxative', ',', 'by', 'carter-wallace.', '.', '.*', 'bions', '\"', ',', 'for', 'a', 'breath', 'freshener', ',', 'by', 'miles', 'labs', '...', '\"', 'medrol', 'acne', 'lotion', '\"', ',', 'for', 'a', 'medicated', 'skin', 'prepara', '~', 'tion', ',', 'by', 'upjohn', '...*', 'sucaryl', 'sugar', '\"', ',', 'for', 'a', 'low', 'calorie', 'sweetener', ',', 'by', 'abbott.', '.', '.\"', 'extra', 'hours', '\"', 'and', '\"', 'stay', 'free', '\"', ',', 'for', 'sanitary', 'napkins', ',', 'by', 'johnson', '&', 'johnson', '...', '“', 'second', 'wind', '\"', ',', 'for', 'keep', 'alert', 'wafers', ',', 'py', 'bristol-myers.', '--.', '\"', 'teddy', 'bare', '\"', ',', 'for', 'sun', 'tanning', 'lotion', ',', 'by', \"chesebrough-pond's.\", 'g', 'an', 'eyeglass', 'repair', 'kit', 'that', 'comes', 'complete', 'with', 'nose', 'and', 'temple', 'comfort', 'pads', ',', 'temple-tites', ',', 'replacement', 'screws', ',', 'precision', 'screw-driver', 'and', 'magnifying', 'glass', 'is', 'being', 'marketed', 'py', 'evans', 'case', 'co.', '$', '1.49.', 'a', 'products', 'in', 'test', 'markets', ':', '\"', 'shield', '\"', ',', 'a', 'deodorant', 'soap', ',', 'by', 'lever', 'bros', '...', '*\"', 'vitamite', '\"', ',', 'a', 'vitamin-fortified', 'thirst', 'quencher', 'drink', 'in', 'powder', 'form', ',', 'by', 'gold', 'medal', 'products', '...', '\"', 'help', '\"', ',', 'a', 'drink', 'concentrate', 'for', 'children', ',', 'by', 'h.', 'j.', 'heinz', '...\"', 'vantage', '\"', 'cigarets', 'by', 'reynolds.', 's', 'a', 'humidifier', 'with', 'a', 'spout', 'that', 'rotates', '130', '°', ',', 'enabling', 'users', 'to', 'direct', 'the', 'mist', 'to', 'any', 'desired', 'area', ',', 'is', 'available', 'from', 'devilbiss.', 'called', 'the', '\"', 'director', '\"', ',', 'it', 'retails', 'at', '$', '17.95.', 'a', 'reversing', 'the', 'trend', 'toward', 'higher', 'prices', ',', 'm.', 'hohner', ',', 'inc', ',', 'has', 'reduced', 'the', 'suggested', 're', '-', 'tail', 'price', 'of', 'the', '“', 'american', 'ace', '\"', 'harmonica', '‘', 'from', '$', '1.50', 'to', '$', '1', '.', '~', 'philip', 'morris.', '100', 'park', 'avenue', ',', 'new', 'york,n.', 'y', ',', '10017.', 'telephone', '(', '212', ')', '679-1800', 'oe', 'april', '5', ',', '1982', 'mr.', 'hans', 'g.', 'storr', 'treasurer', 'the', 'council', 'for', 'tobacco', 'research-u.s.a.', ',', 'inc.', '|', '110', 'bast', '59th', 'street', '.', 'new', 'york', ',', 'new', 'york', '10022', 'dear', 'mr.', 'storr', ':', 'enclosed', 'is', 'philip', 'morris', 'incorporated', \"'s\", 'check', 'for', '$', '414,296.00', 'representing', 'our', 'company', \"'s\", 'eighth.', 'and', 'ninth', 'installments', 'of', '1981', 'dues', '...', 'sincerely', ',', 'de', 'slt', 'cee', 'helen', 'frustace', 'enclosure', 'marlboro.', 'benson', '&', 'hedges', 'merit', 'virginia', 'slims', '©', 'parliament', 'miller', 'high', 'life', 'lite', 'lowenbrau', '7up', '_', '“', 'diet', '7up', 'lungcancer', 'called', 'big', 'killer', 'of', '2-pack-a-day', 'smokers', 'by', 'pierre', 'c.', 'fraley', 'survey.', 'careinoma', 'of', 'the', 'lunr', 'of', 'the', 'bulletin', 'stajs', 'laccounted', 'for', '12', 'per', 'cent', 'of', 'all', 'auantic', 'city', ',', 'june', '6', '--', 'the', '|', '928ths', 'in', 'this', 'group', 'and', 'was', 'sec', '-', 'american', 'cancer', 'socicty', \"'s\", 'long', '-', 'ond', 'only', 'beroneny', 'artery', 'dis', 'range', 'study', 'of', '188.000', 'men', 'be', '-', '|', '“\"', 'srne', 'death', 'rate', 'from', 'carcinoma', 'tween', 'the', 'ages', 'of', '50', 'and', '70', 'con.', 'of', 'the', 'lung', 'increases', 'with', 'the', 'tinues', 'to', 'indicate', 'that', 'lung', 'can', '-', 'lamount', 'of', 'cigarette', 'smoking.', 'cer', 'and', 'cigarette', 'smoking', 'go', 'hand-in-hand.', 'less', 'with', 'pipe', 'smokers', 'dr.', 'e.', 'cuyler', 'hammond', ',', 'diree-j', 'lung', 'cancer', 'also', 'appears', 'to', 'be', 'tor', ',', 'and', 'dr.', 'daniel', 'horn', ',', 'assist', ':', '{', 'associated', 'with', 'pipe', 'smoking', 'but', 'ant', 'director', 'of', 'statistical', 're', '‘', 'to', 'a', 'far', 'lesser', 'degree', 'than', 'with', 'search', ',', 'reported', 'today', 'at', 'the', '{', 'cigarette', 'smoking.', 'there', 'seems', '104th', 'annual', 'meeting', 'of', 'the', '!', 'to', 'be', 'no', 'significant', 'tieup', 'between', 'american', 'medical', 'association', 'on', '{', 'cigar', 'smoking', 'and', 'lung', 'cancer.', 'a', '2-month', 'follow-up', 'on', 'the', 'the', 'rate', 'of', 'lung', 'cancer', 'was', 'smoking', '‘', 'habits', 'and', 'fate', 'of', 'menyhigh', 'in', 'cigarette', 'smokers', 'and', 'low', 'in', 'this', 'age', 'group.', 'in', 'non-smokers', 'regardless', 'of', 'the', 'report', 'is', 'an', 'extension', 'of', '|', 'whether', 'they', 'lived', 'in', 'a', 'city', 'or', 'in', 'the', 'ene', 'at', 'the', 'ama', 'convention', '!', 'the', 'country.', 'however', ',', 'smoking', 'last', 'year', 'dealing', 'with', 'overalljhabits', 'were', 'not', 'able', 'to', 'account', 'death', 'rates', 'that', ',', 'caused', 'tobacco', '}', 'for', 'all', 'of', 'the', 'higher', 'death', 'rate', 'stocks', 'to', 'plummet', 'a', 'total', 'of', '$', '77', ',-|', 'from', 'lung', 'cancer', 'in', 'urban', 'areas', '000,000', 'in', 'a', 'few', 'days.', 'oo', 'with', 'rural', 'areas.', 'during', 'the', 'months', 'of', 'the', 'bare', 'among', 'non-smokers', '|', 'survey', 'there', 'were', '152', 'deaths', 'today', \"'s\", 'report.', 'concentrating', 'from', 'earcinoma', 'of', 'the', 'lung', 'mainly', 'on', 'the', 'most', 'widespread', 'among', 'the', '108000', 'men', 'who', 'said', 'type', 'of', 'lung', 'cancer', ',', 'carcinoma', ',', 'cam', ':', 'to', 'these', 'conclusions', ':', 'ratio', 'of', '145', 'out', 'of', 'every', '100,000.', 'compares', 'with', 'a', 'death', 'rate', 'men', 'who', 'have', 'never', 'smoked.', '”', 'it', 'is', '“', 'an', 'important', 'cause', 'of', 'death', 'among', 'men', 'i', '“', 'in', 'this', 'group', 'the', 'rate', 'for', 'men', 'smoking', 'twoor', 'more', ',', '.', 'packs', 'of', 'cigarettes', 'a', 'day.', '\"', 'iwith', 'history', 'of', 'regular', 'cigar-there', 'were', '4430', 'men', 'who', 'cle', 'smoking', 'was', 'about', '29', 'times', 'smoked', 'two', 'packs', 'or', 'more', 'in', 'the', '%', '8', 'high', 'as', 'the', 'rate', 'for', 'men', 'who', 'never', 'smoked', ',”', 'the', 'doctors', 're', '-', 'ported.', 'the', 'evening', 'bulletin', 'industryraps', '|\"', 'sue', '\"', '6,isss', 'cancer', 'report', '|', 'ov.', '\"', 'scoerar', 'ars', 'attacks', 'figures', 'new', 'york', ',', 'june', '6', '—(', 'up', ')—', 'timothy', 'b.', 'hartnett', ',', 'chairman', 'of', 'the', 'tobacco', 'industry', 'research', 'comittee', ',', 'today', 'urged', 'smokers', 'mot', 'to', 'be', '“', 'misled', 'by', 'sweeping', 'generalities', '”', 'in', 'a', 'doctors’', 'report', 'on', 'the', 'relationship', 'between', 'jat', 'the', 'start', 'of', 'the', 'survay', 'over', 'three', 'years', 'ago', ',”', 'he', 'sald.', 'hartnett', 'also', 'charged', 'that', 'the', 'quertionnaire', 'used', 'by', 'drs.', 'e', 'cuyler', 'hammond', 'and', 'daniel', 'horn', 'contained', 'bias', '“', 'so', 'great', 'as', 'to', 'make', 'questionable', 'the', 'validity', '{', 'ef', 'any', 'conclusions', '...”', 'same', 'of', 'amoking', 'and', 'lung', 'cancer.', '—', '§', 'uhe', 'questions', 'were', 'yeading', ',', 'hort-hartnett', ',', '@', 'hose', 'organization', ']', 'nett', 'said', ',', 'and', 'use', 'of', 'the', 'term', 'is', 'conducting', 'its', 'own', 'survey', 'into', '|', '‘', 'heavy', 'smoking', '”', 'suggested', 'excess', 'lung', 'cancer', ',', 'charged', 'that', 'the', 're', '-)', 'which', '“', 'doctors', 'generally', 'oppose', 'port', 'releared', 'today', 'in', 'atlantic', '}', '«..', 'in', 'any', 'human', 'ectivity.', 'city', '“', 'ignores', 'important', 'enviror', '-}|', 'laboratory', 'rescareh', 'during', 'the', 'mental', ',', 'georraphical', ',', 'occupation', '-/', 'past', 'year', 'has', 'failed', 'to', ',', 'provide', 'al', ',', 'physical', 'and', 'emotional', 'factors', '/', '@', 'ny', 'proof', 'that', 'smoking', 'causes', 'eflecting', 'disease', 'and', 'longevity.', '”', '|', 'lung', 'cancer.', 'hartnett', 'sald.', 'they', 'smoked', 'regularly.', 'this', 'is', 'ai', 'eg', '“', 'the', 'rate', 'for', 'two-pack-a-day-or-more', 'cigarette', 'smokers', 'is', 'over', '90', 'times', 'as', 'high', 'as', 'the', 'rate', 'for', 'men', 'who', 'have', 'never', 'smoked', ',”', 'the', 'report', 'went', 'on.', '“', 'the', 'rate', 'for', 'men', 'who', 'have', 'given', 'up', 'cigarette', 'smoking', 'is', '14', 'times', 'as', 'high', 'as', 'the', 'rate', 'for', 'men', 'who', 'have', 'never', 'smoked', 'but', 'only', 'half', 'as', 'high', 'as', 'for', 'men', 'who', 'were', 'smoking', 'less', 'than', 'a', 'pack', 'of', 'cigarettes', 'a', 'da', ')', 'at', 'the', 'time', 'of', 'que-tinnine.', '”', '|', 'in', 'the', 'light', 'of', 'these', 'findings.', '{', 'ir', 'doctors', 'said', ',', 'it', 'seems', 'prob-able', 'that', 'giving', 'up', 'smoking', 'even', 'after', 'years', 'of', 'regular', 'smoking', 'may', 'result', 'in', 'a', 'reduction', 'in', 'the', 'rivk', 'of', 'developing', 'sung', 'cancer.', 'however', ',', 'the', 'number', 'of', 'cases', ':', 'mow', 'available', 'for', 'detailer', '!', 'analy', '-*', 'sis', 'is', 'not', 'great', 'enough', 'to', 'state', 'that', 'such', 'a', 'conclusion', 'has', 'been', ';', 'proved', 'beyond', 'reasonable', 'doubt.', '\"', 'more', 'evidence', 'is', 'needed', ',', 'they’', 'sai', ':', 'survey', 'of', 'specialists', 'tn', 'another', 'type', 'of', 'survey', 'con', '-|', 't', 'ducied', 'by', 'the', 'american', 'cancer', 'society', ',', 'a', 'majority', 'of', 'chest', 'sur-geons', ',', 'cancer', 'researchers', 'and', 'pathologists', 'who', 'were', 'questiou-ed', 'said', 'they', 'believed', 'heavy', 'agar-ette', 'smoking', 'may', 'lead', 'to', 'lung', 'cancer.', 'dr.', 'charles', 's.', 'cameron', ',', 'medi-1', 'and', 'scientific', 'director', 'of', 'the', 'acs', ',', 'reported', 'on', 'the', 'results', 'of', 'a', 'prg', 'sued', '?', 'the', 'evening', 'bulletin', 'fniladelphia', ',', 'penna.', 'june', '6', ',', '1955', 'sixty-three', 'per', 'cent', 'of', 'the', 'chest', 'surgeons.', '54', 'per', 'cent', 'of', 'the', 'researchers', 'and', 'half', 'of', 'the', 'path-ologists', 'checkei', '“', 'yes', '”', 'to', 'the', 'statement', 'that', 'heavy', 'smoking', 'of', 'cigarettes', 'may', 'lead', 'to', 'lung', 'can-cer', ',', 'the', '“', 'no', \"'s\", '”', 'ranged', 'from', 'four', 'to', 'seven', 'per', 'cent.', 'the', 'remainder', 'were', 'uncertain.', 'the', '\\\\-', 'o', 'reports', 'were', 'presented', 'at', 'a', 'symposium', 'on', '@', 'ancer', 'and', 'medicine', 'at', 'the', 'opening', 'session', '{', 'of', 'the', 'ama', 'convention.', '25,000', 'are', 'attending', 'some', '13.000', 'doctors', 'and', '12,000', 'guests', 'are', 'scheduled', 'to', 'attend', 'the', 'week-long', 'series', 'of', 'meetings.', 'on', 'tuesday', 'evening.', 'dr.', 'elmer', '|', 'hess.', 'of', 'erie', ',', 'will', 'be', 'inaugurated', 'as', 'president', 'of', 'the', 'ama.', 'he', 'suce', 'ceeds', 'dr.', 'walter', 'b.', 'martin', ',', 'of', 'norfolk', ',', 'va.', 'another', 'highlight', 'of', 'the', 'con-vention', 'will', 'be', 'a', 'symposium', 'on', 'the', 'contro', '!', 'of', 'polio.', 'among', 'the', 'experts', 'scheduled', 'to', 'participate', 'are', 'dr.', 'jonas', 'e.', 'salk', ',', 'developer', 'of', 'the', 'polio', 'vaccine', ';', 'dr.', 'leonard', 'a.', 'scheele', ',', 'surgeon', 'general', 'of', 'the', 'u.', 's.', 'public', 'health', 'service.', 'and', 'dr.', 'thomas', 'francis', ',', 'jr', ',', 'of', 'the', 'university', 'of', 'michigan.', 'who', 're-ported', 'on', 'the', 'success', 'of', 'the', 'vac', 'cine', 'used', 'in', 'a', 'mass', 'test', 'last', 'year.', 'detroit', 'free', 'press', 'detroit', ',', 'michigan', 'june', '7', ',', '1955', 'doctors', 'file', 'report', 'cancer', 'danger', 'seen', 'in', 'use', 'of', 'whisky', 'gpoelal', 'to', 'the', 'free', 'press', 'atlantic', 'city', '—', 'whisky-drinking', 'has', 'been', 'added', 'to', 'smoking', 'as', 'a', 'possible', 'cause', 'of', 'cancer', ',', 'three', 'physicians', 'revealed', 'here', 'monday', 'in', 'a', 'report', 'to', 'the', 'american', 'medical', 'association.', 'the', 'risk', 'of', 'tons', 'greatiy', 'or', 'voice', 'larynx', ',', '2', 'cia', ',', 'by', 'haa', 'ema', 'with', 'heavy', 'drinking.', 'port', 'on', 'interviews', 'in', 'sweden', ',', 'india', 'an', '¢', 'the', 'united', 'states', ',', 'ben', 'more', 'than', 'siz', 'eamokers', ',', 'they', 'found', ',', 'ut', 'the', 'same', 'risk', 'as', 'men', 'who', 'amoke', '16', 'to', '34', 'cigarets', '——', 'ae', 'and', 'run', 'oking', 'alone', ',', 'or', 'com', '-/', 'dally', ',', 'from', 'this', 'and', 'other', 'studies', ',', 'opinion', 'research', 'authorities', '”', 'con', '-', 'they', 'sald', 'the', 'risk', 'of', 'cancer', 'inj', 'sidered', 'that', 'the', 'poll', 'was', '“', 'biased', ',', 'tha', 'larynx', 'increases', 'with', 'tho', '/', 'nonscientific', 'q', '@', 'mount', 'of', 'elgarets', 'amoked.', 'cigariahortcomings', 'and', 'and', 'filled', 'with', 'defect', '”', 'sen.', 'bs', 'everett', 'jordan', ':', 'repe', 'le', 'h.', 'fountain', ':', 'rep.', 'harley', 'staggers', ':', 'rep.', 'edward', 'i.koch', ':', 'hkeo485294', '“', 'regarded', 'the', 'fcc', 'ban', 'as', '‘', 'an', 'unwarranted', ',', '111-advised', 'and', 'improper', 'effort', 'to', 'extend', 'governnent', 'control', 'over', 'business', 'and', 'industry', 'by', 'administrative', 'dictation.', '\"\"]', 'regard', 'the', 'proposal', 'of', 'the', 'federal', 'communications', 'commission', 'for', 'a', 'ban', 'on', 'advertising', 'of', 'cigarettes', 'through', 'television', 'and', 'radio', 'media', 'as', 'an', 'unwarranted', ',', '111l', '~', 'advised', 'and', 'improper', 'effort', 'to', 'extent', 'government', 'control', 'over', 'business', 'and', 'industry', 'by', 'administrative', 'dictation.', '\"', 'tle', '4s', 'an', 'extention', 'of', 'earlier', 'efforts', ',', 'successfully', 'resisted', 'so', 'far', 'by', 'congress', ',', 'by', 'both', 'the', 'federal', 'trade', 'commission', 'and', 'the', 'fcc', 'to', 'exereise', 'control', 'over', 'the', 'tobacco', 'industry', 'beyond', 'the', 'extent', 'of', 'their', 'authority', 'and', 'in', 'an', 'area', 'properly', 'reserved', 'for', 'legislative', 'jurisdiction', ',', '’', '(', 'upi', '2', '/', '5', '/', '69', ')', '\"', 'said', 'he', 'knew', 'of', 'no', 'legal', 'authority', 'by', 'which', 'fcc', 'could', 'enforce', 'its', 'proposed', 'ban', 'on', 'broadcast', 'cigarette', 'advertising.', '\"', '(', 'upi', '2', '/', '5', '/', '69', ')', '\"', 'forecasting', 'early', 'hearings', 'on', 'the', 'issue', ',', 'offered', 'a', 'critical', 'comment', 'that', 'seemed', 'to', 'reflect', 'a', 'common', '‘', 'attitude', 'on', 'the', 'part', 'of', 'committee', 'nembers', ',.', '\"\\'', 't', 'think', 'some', 'of', 'the', 'regulatory', 'agencies', 'are', 'doing', 'sone', 'of', 'those', 'things', 'the', 'wrong', 'way.', '.', '\"\\'', 'rhey', \"'ve\", 'been', 'guilty', 'of', 'it', 'before', '=-', 'taking', 'a', 'stand', 'of', 'this', 'kind', 'on', 'an', 'issue', 'which', 'they', 'know', 'the', 'congress', 'would', 'probably', 'be', 'considering', 'shortly.', '1', 'do', \"n't\", 'think', 'congress', 'likes', 'this', 'approach', '--', 'and', 'that', 'is', 'without', 'regard', 'to', 'the', 'particular', 'issue', 'of', 'cigarette', 'smoking.', '\\'\"', '(', 'upi', '2', '/', '5', '/', '69', ')', '\"', 'a', 'federal', 'communications', 'proposal', 'to', 'ban', 'cigarette', 'advertising', 'from', 'television', 'and', 'radio', 'was', '‘', 'long', 'overdue.’', '\"', 'he', 'will', 'do', 'what', 'he', 'can', 'to', 'whip', 'up', 'congressional', 'support', 'for', 'the', 'fcc', 'proposal', ',', 'he', 'called', 'on', 'members', 'of', 'the', 'public', 'to', 'direct', 'their', 'support', 'to', 'the', 'fcc', '-', 'and', 'their', 'congresamen.', '\"\"', 'we', 'are.', 'going', 'to', 'have', 'a', 'fight', 'on', 'our', 'hands', ',\\'\"', '(', 'upt', '2', '/', '5', '/', '69', ')', '\\\\', 'ff', 'principal', 'investigator', '/', 'program', 'director', '(', 'last', ',', 'first', ',', 'middle', ')', ':', 'biographical', 'sketch', 'give', 'the', 'following', 'information', 'for', 'the', 'key', 'personnel', 'and', 'consultants', 'and', 'collaborators.', 'begin', 'with', 'the', 'principal', 'investigator', '/', 'program', 'director.', 'photocopy', 'this', 'page', 'for', 'each', 'person.', 'position', 'title', 'james', 't.', 'kadonaga', 'associate', 'professor', 'education', '(', 'begin', 'with', 'baccalaureate', 'or', 'other', 'initial', 'professional', 'education', ',', 'such', 'as', 'nursing', ',', 'and', 'include', 'postdoctoral', 'training.', ')', 'year', 'degree', 'conferred', 'field', 'of', 'study', 'institution', 'and', 'location', 'massachusetts', 'institute', 'of', 'technology', '1980', 'chemistry', 'harvard', 'university', '1982', 'chemistry', 'harvard', 'university', '1984', 'chemistry', 'university', 'of', 'california', ',', 'berkeley', 'postdoc', '1984-88', 'biochemistry', 'research', 'and', 'professional', 'experience', ':', 'concluding', 'with', 'present', 'position', ',', 'list', ',', 'in', 'chronological', 'order', ',', 'previous', 'employment', ',', 'experience', ',', 'and', 'honors.', 'key', 'personnel', '!', 'include', 'the', 'principal', 'investigator', 'and', 'any', 'other', 'individuals', 'who', 'participate', 'in', 'the', 'scientific', 'development', 'or', 'execution', 'of', 'the', 'project.', 'key', 'personnel', 'typically', 'will', 'include', 'all', 'individuals', 'with', 'doctoral', 'or', 'other', 'professional', 'degrees', ',', 'but', 'in', 'some', 'projects', 'will', 'include', 'individuals', 'at', 'the', 'masters', 'or', 'baccalaureate', 'level', 'provided', 'they', 'contribute', 'in', 'a', 'substantive', 'way', 'to', 'the', 'scientific', 'development', 'or', 'execution', 'of', 'the', 'project.', 'include', 'present', 'membership', 'on', 'any', 'federal', 'government', 'public', 'advisory', 'committee.', 'list', ',', 'in', 'chronological', 'order', ',', 'the', 'titles', ',', 'all', 'authors', ',', 'and', 'complete', 'references', 'to', 'all', 'publications', 'during', 'the', 'past', 'three', 'years', 'and', 'to', 'representative', 'earlier', 'publications', 'pertinent', 'to', 'this', 'application.', 'if', 'the', 'list', 'of', 'publications', 'in', 'the', 'fast', 'three', 'years', 'exceeds', 'two', 'pages', ',', 'select', 'the', 'most', 'pertinent', 'publications.', 'do', 'not', 'exceed', 'two', 'pages.', 'research', '1980-34', 'graduate', 'student.', 'harvard', 'university.', 'advisor', ':', 'j.', 'r.', 'knowles.', '1984-38', 'postdoctoral', 'research', 'fellow.', 'uc', 'berkeley.', 'advisor', ':', 'r.', 'tjian.', '1988-92', 'assistant', 'professor', 'of', 'biology.', 'university', 'of', 'calfornia', ',', 'san', 'diego.', '1992-present', 'associate', 'professor', 'of', 'biology.', 'university', 'of', 'california', ',', 'san', 'diego.', 'academic', 'honors', '1980', 'alpha', 'chi', 'sigma', 'prize', ';', 'massachusetts', 'institute', 'of', 'technology', '1980', 'american', 'institute', 'of', 'chemists', 'certificate', ';', 'massachusetts', 'institute', 'of', 'technology', '1983-84', 'du', 'pont', 'fellow', ';', 'harvard', 'university', '1984-86', 'fellow', 'of', 'the', 'miller', 'institute', 'for', 'basic', 'research', 'in', 'science', ';', 'uc', 'berkeley', '1986-87.', 'senior', 'fellow', 'of', 'the', 'american', 'cancer', 'society', ',', 'california', 'division', ';', 'uc', 'berkeley', '1987-93', 'lucille', 'p.', 'markey', 'scholar', 'in', 'biomedical', 'sciences', '1989-91', 'eli', 'lilly', 'biochemistry', 'award', '1992-97', 'presidential', 'faculty', 'fellow', 'award', '1994', 'fellow', 'of', 'the', 'american', 'association', 'for', 'the', 'advancement', 'of', 'science', 'scientific', 'activities', '1989-present', 'co-organizer.', 'course', 'on', '\"', 'protein', 'purification', 'and', 'characterization.', '\"', 'held', 'annually', 'at', 'cold', 'spring', 'harbor', 'laboratory.', '1990-present', 'editorial', 'board', 'of', 'protein', 'expression', '&', 'purification.', '1992-94', 'member', 'of', 'national', 'science', 'foundation', 'grant', 'review', 'panel.', '1993-95', 'editorial', 'board', 'of', 'molecular', '&', 'cellular', 'biology.', '1994-present', 'editorial', 'board', 'of', 'genes', '&', 'development.', '1995', 'co-organizer.', 'faseb', 'summer', 'conference', 'on', '“', 'chromatin', 'and', 'transcription.', '\"', '1996', 'co-organizer.', 'faseb', 'summer', 'conference', 'on', '“', 'transcriptional', 'regulation', 'during', 'cell', 'growth', ',', 'differentiation', ',', 'and', 'development.', '”', 'ae', 'phs', '398', '(', 'rev.', '9', '/', '91', ')', '(', 'form', 'page', '6', ')', 'page', '_', 'ff', 'number', 'pages', 'consecutively', 'at', 'the', 'bottom', 'throughout', 'the', 'application.', 'do', 'not', 'use', 'suffixes', 'such', 'as', '3a', ',', '3b', '.', ';', 'james', 't.', 'kadonaga', '—', 'selected', 'relevant', 'publications', '(', 'out', 'of', 'a', 'total', 'of', '40', ')', '10.', 'll', '12.', '13.', '14', ',', '15.', '16.', '17.', '.', '18.', '19.', '20.', 'kadonaga', ',', 'j.', 't.', ',', 'and', 'tjian', ',', 'r.', '(', '1986', ').', 'affinity', 'purification', 'of', 'sequence-specific', 'dna', 'binding', 'proteins.', 'proc.', 'natl.', 'acad.', 'sci.', 'u.s.a.', '83', ',', '5889-5893.', 'kadonaga', ',', 'j.', 't.', ',', 'carner', ',', 'k.', 'r.', ',', 'masiarz', ',', 'f.', 'r.', ',', 'and', 'tjian', ',', 'r.', '(', '1987', ').', 'isolation', 'of', 'cdna', 'encoding', 'transcription', 'factor', 'sp1', 'and', 'functional', 'analysis', 'of', 'the', 'dna', 'binding', 'domain.', 'cell', '51', ',', '1079-1090.', '.', 'kadonaga', ',', 'j.', 't.', ',', 'courey', ',', 'a.', 'j.', ',', 'ladika', ',', 'j.', ',', 'and', 'tjian', ',', 'r.', '(', '1988', ').', 'distinct', 'regions', 'of', 'sp1', 'modulate', 'dna', 'binding', 'and', 'transcriptional', 'activation.', 'science', '242', ',', '1566-1570.', 'kadonaga', ',', 'j.', 't.', '(', '1990', ').', 'assembly', 'and', 'disassembly', 'of', 'the', 'drosophila', 'rna', 'polymerase', 'i', 'complex', 'during', 'transcription.', 'j.', 'biol.', 'chem.', '265', ',', '2624-2631.', 'wampler', ',', 's.', 'l.', ',', 'tyree', ',', 'c.', 'm.', ',', 'and', 'kadonaga', ',', 'j.t.', '(', '1990', ').', 'fractionation', 'of', 'the', 'general', 'rna', 'polymerase', 'ii', 'transcription', 'factors', 'from', 'drosophila', 'embyros.', 'j.', 'biol.', 'chem.', '265', ',', '21223-21231.', 'kerrigan', ',', 'l.', 'a.', ',', 'croston', ',', 'g.', 'e.', ',', 'lira', ',', 'l.', 'm.', ',', 'and', 'kadonaga', ',', 'j.', 't.', '(', '1991', ').', 'sequence-specific', 'transcriptional', 'antirepression', 'of', 'the', 'drosophila', 'kriippel', 'gene', 'by', 'the', 'gaga', 'factor.', 'j.', 'biol.', 'chem', ',', '266', ',', '574-582.', 'kamakaka', ',', 'r.', 't.', ',', 'tyree', ',', 'c.', 'm.', ',', 'and', 'kadonaga', ',', 'j.', 't.', '(', '1991', ')', ',', 'accurate', 'and', 'efficient', 'rna', 'polymerase', 'ii', 'transcription', 'with', 'a', 'soluble', 'nuclear', 'fraction', 'derived', 'from', 'drosophila', 'embyros.', 'proc.', 'natl.', 'acad.', 'sci.', 'usa', '88', ',', '1024-1028.', 'croston', ',', 'g.', 'e.', ',', 'kerrigan', ',', 'l.', 'a.', ',', 'lira', ',', 'l.', ',', 'marshak', ',', 'd.', 'r.', ',', 'and', 'kadonaga', ',', 'j.', 't.', '(', '1991', ').', 'sequenceé-specific', 'antirepression', 'of', 'histone', 'h1-mediated', 'inhibition', 'of', 'basal', 'rna', 'polymerase', 'il', 'transcription.', 'science', '251', ',', '643-649.', 'croston', ',', 'g.', 'e.', ',', 'lira', ',', 'l.', 'm.', ',', 'and', 'kadonaga', ',', 'j.', 't.', '(', '1991', ').', 'a', 'general', 'method', 'for', 'the', 'purification', 'of', 'h1', 'histones', 'that', 'are', 'active', 'for', 'repression', 'of', 'basal', 'rna', 'polymerase', 'ii', 'transcription.', 'protein', 'expression', 'and', 'purification', '2', ',', '162-169.', 'kadonaga', ',', 'j.', 't.', '(', '1991', ').', 'purification', 'of', 'sequence-specific', 'dna', 'binding', 'proteins', 'by', 'dna', 'affinity', 'chromatography.', 'methods', 'enzymol.', '208', ',', '10-23.', 'laybourn', ',', 'p.', 'j.', ',', 'and', 'kadonaga', ',', 'j.', 't.', '(', '1991', ').', 'role', 'of', 'nucleosomal', 'cores', 'and', 'histone', 'h1', 'in', 'regulation', 'of', 'transcription', 'by', 'rna', 'polymerase', 'it.', 'science', '254', ',', '238-245.', 'wampler', ',', 's.', 'l.', ',', 'and', 'kadonaga', ',', 'j.', 't.', '(', '1992', ').', 'functional', 'analysis', 'of', 'drosophila', 'transcription', 'factor', 'itb.', 'genes', '&', 'dev.', '6', ',', '1542-1552.', 'laybourn', ',', 'p.', 'j.', ',', 'and', 'kadonaga', ',', 'j.', 't.', '(', '1992', ').', 'threshold', 'phenomena', 'and', 'long-distance', 'activation', 'of', 'transcription', 'by', 'rna', 'polymerase', 'ii.', 'science', '257', ',', '1682-1685.', 'croston', ',', 'g.', 'e.', ',', 'laybourn', ',', 'p.', 'j.', ',', 'paranjape', ',', 's.', 'm.', ',', 'and', 'kadonaga', ',', 'j.', 't.', '(', '1992', ').', 'mechanism', 'of', 'transcriptional', 'antirepression', 'by', 'gal4-vp16.', 'genes', '&', 'dev.', '6', ',', '2270-2281.', 'kerrigan', ',', 'l.', 'a.', ',', 'and', 'kadonaga', ',', 'j.', 't.', '(', '1992', ').', 'periodic', 'binding', 'of', 'individual', 'core', 'histones', 'to', 'dna', ':', 'inadvertent', 'purification', 'of', 'the', 'core', 'histone', 'h2b', 'as', 'a', 'putative', 'enhancer-binding', 'factor.', 'nucleic', 'acids', 'res.', '20', ',', '6673-6680.', 'croston', ',', 'g.', 'e.', ',', 'and', 'kadonaga', ',', 'j.', 't.', '(', '1993', ').', 'role', 'of', 'chromatin', 'structure', 'in', 'the', 'regulation', 'of', 'transcription', 'by', 'rna', 'polymerase', 'ii.', 'curr.', 'opin.', 'cell', 'biol.', '5', ',', '417-423.', 'kamakaka', ',', 'r.', 't.', ',', 'and', 'kadonaga', ',', 'j.', 't.', '(', '1993', ').', 'biochemical', 'analysis', 'of', 'the', 'role', 'of', 'chromatin', 'structure', 'in', 'the', 'regulation', 'of', 'transcription', 'by', 'rna', 'polymerase', 'il.', 'cold', 'spring', 'harbor', 'symp.', 'quant.', 'biol.', '58', ',', '205-212.', 'tyree', ',', 'c.', 'm.', ',', 'george', ',', 'c.', 'p.', ',', 'devito', ',', 'l.', 'm.', ',', 'wampler', ',', 's.', 'l.', ',', 'dahmus', ',', 'm.', 'e.', ',', 'zawel', ',', 'l.', ',', 'and', 'kadonaga', ',', 'j.', 't.', '(', '1993', ').', 'identification', 'of', 'minimal', 'set', 'of', 'proteins', 'that', 'is', 'sufficient', 'for', 'accurate', 'initiation', 'of', 'transcription', 'by', 'rna', 'polymerase', 'ii.', 'genes', '&', 'dev.', '7', ',', '1254-1265.', 'kamakaka', ',', 'r.', 't.', ',', 'bulger', ',', 'm.', ',', 'and', 'kadonaga', ',', 'j.', 't.', '(', '1993', ').', 'potentiation', 'of', 'rna', 'polymerase', 'ii', 'transcription', 'by', 'gal4-vp16', 'during', 'but', 'not', 'after', 'dna', 'replication', 'and', 'chromatin', 'assembly.', 'genes', '&', 'dev.', '7', ',', '1779-1795.', 'paranjape', ',', 's.', 'm.', ',', 'kamakaka', ',', 'r.', 't.', ',', 'and', 'kadonaga', ',', 'j.', 't.', '(', '1994', ').', 'role', 'of', 'chromatin', 'structure', 'in', 'the', 'regulation', 'of', 'transcription', 'by', 'rna', 'polymerase', 'it.', 'annu.', 'rev.', 'biochem.', '63', ',', '265-297.', '4']\n"
     ]
    }
   ],
   "source": [
    "contractions_full = []\n",
    "for counter, text in enumerate(ocr):\n",
    "    contractions = split_contractions(word_tokenizer(text))\n",
    "    for element in contractions:\n",
    "        element = element.lower()\n",
    "        contractions_full.append(element)\n",
    "target_vocab = contractions_full\n",
    "print(contractions_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6020\n"
     ]
    }
   ],
   "source": [
    "emb_dim =100\n",
    "matrix_len = len(target_vocab)\n",
    "print(matrix_len)\n",
    "weights_matrix = np.zeros((matrix_len, 100))\n",
    "words_found = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2idx = {}\n",
    "for i, word in enumerate(target_vocab):\n",
    "    corpus2idx[word] = i\n",
    "    try: \n",
    "        weights_matrix[i] = glove[word]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    print(type(weights_matrix))\n",
    "    num_embeddings, embedding_dim = weights_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': torch.tensor(weights_matrix)})\n",
    "    #torch.tensor(emb_layer.load_state_dict({'weight': weights_matrix}), dtype=torch.long)\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset creation with image directory, image -> 'RGB' -> transformed to Mobilenetv2 input, Ocr,\n",
    "# Class and Segmentation\n",
    "\n",
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.RandomCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])}\n",
    "#Independent train and test transformations can be done\n",
    "\n",
    "class H5Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, hdf5_file, data_transforms):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.h5_file = h5py.File(hdf5_file, \"r\")\n",
    "        self.data = self.h5_file.get('train_img')\n",
    "        self.target = self.h5_file.get('train_labels')\n",
    "        self.ocr = self.h5_file.get('train_ocrs')\n",
    "        self.data_transforms = data_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = self.data[idx,:,:,:],\n",
    "        img = Image.fromarray(img[0].astype('uint8'), 'RGB')\n",
    "        #doc_class = torch.from_numpy(self.target[idx,:,:,:]).float()\n",
    "        doc_class = self.target[idx]\n",
    "        doc_class = doc_class.astype(np.uint8)\n",
    "        doc_class = torch.tensor(doc_class)\n",
    "        \n",
    "        ocr_text = self.ocr[idx]\n",
    "        \n",
    "\n",
    "        if self.data_transforms is not None:\n",
    "            try:\n",
    "                image = self.data_transforms(img)\n",
    "            except:\n",
    "                print(\"Cannot transform image: {}\")\n",
    "        \n",
    "        ocr = ocr_text\n",
    "        tokenization_ocr_full = []\n",
    "        tokenization_ocr = split_contractions(word_tokenizer(ocr))\n",
    "        for element in tokenization_ocr:\n",
    "            element = element.lower()\n",
    "            tokenization_ocr_full.append(element)\n",
    "        \n",
    "        #print(tokenization_ocr_full[0])\n",
    "        #print(tokenization_ocr_full)\n",
    "        \n",
    "        \n",
    "        sample = {'image': image, 'class': doc_class, 'ocr': tokenization_ocr_full}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_dataset = H5Dataset(hdf5_file='./HDF5_files/hdf5_10.hdf5', data_transforms=data_transforms['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(h5_dataset, batch_size=1,\n",
    "                        shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, weights_matrix):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        \n",
    "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, True)\n",
    "        \n",
    "        D = embedding_dim\n",
    "        #V = args.embed_num\n",
    "        #D = 2048 #embed_dim, 4196 for doc_embeddings\n",
    "        C = 10 #class_num\n",
    "        Ci = 1\n",
    "        Co = 100 #kernel_num -> number of kernel with the same size\n",
    "        Ks = [3,4,5] #kernel_sizes -> size = number of words\n",
    "\n",
    "        #self.embed = nn.Embedding(V, D)\n",
    "        # self.convs1 = [nn.Conv2d(Ci, Co, (K, D)) for K in Ks]\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        self.conv13 = nn.Conv2d(Ci, Co, (3, D))\n",
    "        self.conv14 = nn.Conv2d(Ci, Co, (4, D))\n",
    "        self.conv15 = nn.Conv2d(Ci, Co, (5, D))\n",
    "        '''\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        \n",
    "        #Output will be size (1,Ks*Co) -> Maxpool will get one ĉ value =  max(c_1,c_2...), where c_i is\n",
    "        #the result of the convolution operation of the kernel over the input\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.embed(x)  # (N, W, D)\n",
    "        \n",
    "        #if self.args.static:\n",
    "            #x = Variable(x)\n",
    "        \n",
    "        #print('CNN Before embedding',x.shape)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        #print('CNN After embedding',x.shape)\n",
    "\n",
    "        x = x.unsqueeze(0)  # (N, Ci, W, D)\n",
    "        x = x.unsqueeze(0)\n",
    "        #print('CNN unsqueeze',x.shape)\n",
    "        \n",
    "        \n",
    "        #print(x.shape)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
    "        \n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "        \n",
    "\n",
    "        x = torch.cat(x, 1) #[1,100] + [1,100] + [1,100] = [1,300]\n",
    "        \n",
    "        #print('After cat', x.shape)\n",
    "\n",
    "        '''\n",
    "        x1 = self.conv_and_pool(x,self.conv13) #(N,Co)\n",
    "        x2 = self.conv_and_pool(x,self.conv14) #(N,Co)\n",
    "        x3 = self.conv_and_pool(x,self.conv15) #(N,Co)\n",
    "        x = torch.cat((x1, x2, x3), 1) # (N,len(Ks)*Co)\n",
    "        '''\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = x\n",
    "        #logit = self.fc1(x)  # (N, C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mega NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "__all__ = ['MobileNetV2', 'mobilenetv2_19']\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, expansion=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, inplanes*expansion, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes*expansion)\n",
    "        self.conv2 = nn.Conv2d(inplanes*expansion, inplanes*expansion, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False, groups=inplanes*expansion)\n",
    "        self.bn2 = nn.BatchNorm2d(inplanes*expansion)\n",
    "        self.conv3 = nn.Conv2d(inplanes*expansion, planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, text_model, num_classes=16):\n",
    "        self.inplanes = 32\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 16, layers[0], stride=1, expansion = 1)\n",
    "        self.layer2 = self._make_layer(block, 24, layers[1], stride=2, expansion = 6)\n",
    "        self.layer3 = self._make_layer(block, 32, layers[2], stride=2, expansion = 6)\n",
    "        self.layer4 = self._make_layer(block, 64, layers[3], stride=2, expansion = 6)\n",
    "        self.layer5 = self._make_layer(block, 96, layers[4], stride=1, expansion = 6)\n",
    "        self.layer6 = self._make_layer(block, 160, layers[5], stride=2, expansion = 6)\n",
    "        self.layer7 = self._make_layer(block, 320, layers[6], stride=1, expansion = 6)\n",
    "        self.conv8 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, bias=False)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.conv9 = nn.Conv2d(1280,num_classes, kernel_size=1, stride=1, bias=False)\n",
    "        \n",
    "        #Added\n",
    "        #Fully connected\n",
    "        self.fc1 = nn.Linear(310, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "        self.text_model = text_model\n",
    "                \n",
    "\n",
    "    #def conv_and_pool(self, x, conv):\n",
    "        #x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
    "        #x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        #return x\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride, expansion):\n",
    "\n",
    "        downsample = nn.Sequential(\n",
    "            nn.Conv2d(self.inplanes, planes,\n",
    "                      kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride=stride, downsample=downsample, expansion=expansion))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, expansion=expansion))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, x2): #NN input -> Image + ocr text\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "\n",
    "        x = self.conv8(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.conv9(x)\n",
    "        \n",
    "        #print('conv9 output', x.shape)\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "        \n",
    "        \n",
    "        #print(x.size(0))#1Xnum_classes size\n",
    "        \n",
    "        #print('mobilenet output', x.shape)\n",
    "        \n",
    "        \n",
    "        x2 = self.text_model(x2)\n",
    "        \n",
    "        #print('CNN Text output',x2.shape)\n",
    "        \n",
    "        #print('Text model output (without last layer)', x2.shape)\n",
    "                \n",
    "        x2 = torch.cat((x,x2),1)\n",
    "        \n",
    "        x2 = self.fc1(x2)\n",
    "        \n",
    "        #print('MegaNet output',x2)\n",
    "        \n",
    "        #print('Output shape', x2.shape)\n",
    "\n",
    "        return x2\n",
    "\n",
    "\n",
    "def mobilenetv2_19(text_model, **kwargs):\n",
    "    \"\"\"Constructs a MobileNetV2-19 model.\n",
    "    \"\"\"\n",
    "    model = MobileNetV2(Bottleneck, [1, 2, 3, 4, 3, 3, 1], text_model, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mega NN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# get model\n",
    "text_model = CNN_Text(weights_matrix)\n",
    "model = mobilenetv2_19(text_model, num_classes = 10)\n",
    "#print(model)\n",
    "# define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.00004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3103"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus2idx['oe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/15], loss 3.078718662261963\n",
      "[Epoch 1/15], loss 4.647356986999512\n",
      "[Epoch 2/15], loss 1.0268683433532715\n",
      "[Epoch 3/15], loss 2.71111798286438\n",
      "[Epoch 4/15], loss 0.8710904121398926\n",
      "[Epoch 5/15], loss 0.40261173248291016\n",
      "[Epoch 6/15], loss 0.9874954223632812\n",
      "[Epoch 7/15], loss 0.1757526397705078\n",
      "[Epoch 8/15], loss 0.35725927352905273\n",
      "[Epoch 9/15], loss 0.11348152160644531\n",
      "[Epoch 10/15], loss 0.021294593811035156\n",
      "[Epoch 11/15], loss 0.020475387573242188\n",
      "[Epoch 12/15], loss 0.03648185729980469\n",
      "[Epoch 13/15], loss 0.014877796173095703\n",
      "[Epoch 14/15], loss 0.06191205978393555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe7a2349518>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "max_epochs = 15\n",
    "optimizer = optimizer_ft\n",
    "batch_size=1\n",
    "running_loss = 0.0\n",
    "steps = 0\n",
    "loss_values = []\n",
    "epoch_values = []\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    running_loss = 0\n",
    "    # Training\n",
    "    for local_batch in dataloader:\n",
    "        word_list = []\n",
    "        for i, word in enumerate(local_batch['ocr']):\n",
    "            word = local_batch['ocr'][i][0]\n",
    "            word_list.append(word)\n",
    "        \n",
    "            \n",
    "        #ocr_text = torch.tensor([corpus2idx[w] for w in local_batch['ocr']], dtype=torch.long)\n",
    "        ocr_text = [corpus2idx[w] for w in word_list]\n",
    "        ocr_text = torch.tensor(ocr_text)\n",
    "        #print(ocr_text.shape)\n",
    "        image, labels = Variable(local_batch['image']), Variable(local_batch['class'])\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        #print(local_batch['image_dir'])\n",
    "\n",
    "        # forward\n",
    "        outputs = model(image, ocr_text)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        #print(preds, labels.long())\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        #print(outputs)\n",
    "\n",
    "        # backward + optimize only if in training phase\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #running_loss += loss.data[0]\n",
    "        steps += 1\n",
    "        if steps % 100 == 0:\n",
    "            #save(model,'./snapshot/', 'model', steps)\n",
    "            pass\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    loss_values.append(running_loss/10)\n",
    "    epoch_values.append(epoch)\n",
    "\n",
    "    #print(outputs)\n",
    "    print('[Epoch {}/{}], loss {}'.format(\n",
    "                      epoch, max_epochs,loss_values))\n",
    "\n",
    "\n",
    "plt.plot(epoch_values, loss_values, '--', color=\"#111111\",  label=\"Training score\")\n",
    "        \n",
    "#save(model,'./snapshot/', 'model', steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
